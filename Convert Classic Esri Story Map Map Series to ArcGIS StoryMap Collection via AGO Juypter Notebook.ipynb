{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Classic Esri StoryMap Series (Tabbed Layout)\n",
    "Fetch JSON from an ArcGIS Online hosted Classic Esri Story Map Series App and convert each tab/bullet/accordion into its own ArcGIS StoryMap with the cover supressed. Once converted, each ArcGIS StoryMap will need to be opened in a browser tab in order to complete the Story Checker. Once all are published, an ArcGIS StoryMap Collection is created that contains the converted app to replicate the classic app look and feel. Note: Any entries that were hidden in the classic app will be published and will be visible by default. If it is desired that they not appear they can be removed from the Collection after publishing. Also, as there is not equivalent to the accordion layout, these layouts will be converted to the Tabbed format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO - create conversion tool for classic swipe (second tab in Katrina story)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:  3.12.11 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 12:58:53) [MSC v.1929 64 bit (AMD64)]\n",
      "ArcGIS for Python API / StoryMap module version:  2.4.1.3\n"
     ]
    }
   ],
   "source": [
    "# Import packages, config, AGO authentication and helper functions\n",
    "from bs4 import BeautifulSoup, NavigableString, Tag\n",
    "from arcgis.apps.storymap import StoryMap, Themes, Image, Video, Audio, Embed, Map, Button, Text, Gallery, Timeline, Sidecar, Code, Table, TextStyles, Collection, CollectionNavigation\n",
    "import arcgis\n",
    "from arcgis.gis import GIS, Item\n",
    "from PIL import Image as PILImage\n",
    "from PIL import ImageStat\n",
    "from io import BytesIO\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import matplotlib.colors as mcolors\n",
    "import tempfile\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import IntProgress\n",
    "import re, json, requests, sys, time, os, subprocess\n",
    "from copy import deepcopy\n",
    "\n",
    "# Set Pandas dataframe display options\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns',1000)\n",
    "\n",
    "# Print Python and ArcGIS for Python versions\n",
    "# since things can change between versions\n",
    "print(f\"Python version: \",sys.version)\n",
    "print(\"ArcGIS for Python API / StoryMap module version: \",arcgis.__version__)\n",
    "\n",
    "# Set to false if running locally and authenticate separately\n",
    "agoNotebook = False\n",
    "\n",
    "# Connect to ArcGIS Online\n",
    "if agoNotebook:\n",
    "    # Define the GIS\n",
    "    gis = GIS(\"home\")\n",
    "    print(\"Successfully logged in as: \" + gis.properties.user.username, \"(role: \" + gis.properties.user.role + \")\")\n",
    "    \n",
    "## Helper functions\n",
    "\n",
    "default_thumbnail_path = \"https://cdn-a.arcgis.com/cdn/1BE082D/js/arcgis-app-components/arcgis-app/assets/arcgis-item-thumbnail/storymap.png\"\n",
    "\n",
    "# Collect map extents for troubleshooting thumbnail generation\n",
    "map_extents = {}\n",
    "\n",
    "\n",
    "def fetch_classic_storymap_data(classic_storymap_id, gis):\n",
    "    classic_item = Item(gis=gis, itemid=classic_storymap_id)\n",
    "    classic_data = Item.get_data(classic_item)\n",
    "    if classic_data == {}:\n",
    "        raise ValueError(\"ERROR: StoryMap to be converted must be hosted on ArcGIS Online.\")\n",
    "    elif isinstance(classic_data, dict):\n",
    "        classic_item_data = classic_data\n",
    "    else:\n",
    "        classic_item_data = json.loads(classic_data)\n",
    "    return classic_item, classic_item_data\n",
    "\n",
    "def extract_story_settings(classic_item_data):\n",
    "    settings = classic_item_data[\"values\"][\"settings\"]\n",
    "    title = classic_item_data[\"values\"].get(\"title\", \"Untitled StoryMap\")\n",
    "    subtitle = classic_item_data[\"values\"].get(\"subtitle\", \"\")\n",
    "    type = settings[\"layout\"][\"id\"]\n",
    "    panel_position = settings[\"layoutOptions\"][\"panel\"][\"position\"]\n",
    "    theme = settings[\"theme\"]\n",
    "    entries = classic_item_data[\"values\"][\"story\"][\"entries\"]\n",
    "    return title, subtitle, type, panel_position, theme, entries\n",
    "\n",
    "def determine_theme(theme):\n",
    "    classic_name = theme[\"colors\"].get(\"name\", \"No classic theme name\")\n",
    "    group = theme[\"colors\"][\"group\"]\n",
    "    if group == \"dark\":\n",
    "        return classic_name, Themes.OBSIDIAN\n",
    "    elif group == \"light\":\n",
    "        return classic_name, Themes.SUMMIT\n",
    "    else:\n",
    "        return classic_name, Themes.SUMMIT\n",
    "\n",
    "def process_entry(gis, entry, default_thumbnail_path, extents_dict=None, entry_index=None):\n",
    "    entry_title = entry.get(\"title\")\n",
    "    media_info = entry.get(\"media\", {})\n",
    "    media_type = media_info.get(\"type\")\n",
    "    main_stage_content = None\n",
    "    thumbnail_path = None\n",
    "    invalid_webmap = False\n",
    "    image_url = None\n",
    "    print_service_responses = None\n",
    "\n",
    "    if media_type == \"webmap\":\n",
    "        webmap_id = media_info.get('webmap', {}).get('id')\n",
    "        webmap_from_json = build_webmap_from_json(gis, media_info)\n",
    "        # Capture extent for troubleshooting\n",
    "        extent = None\n",
    "        if webmap_from_json and \"mapOptions\" in webmap_from_json and \"extent\" in webmap_from_json[\"mapOptions\"]:\n",
    "            extent = webmap_from_json[\"mapOptions\"][\"extent\"]\n",
    "        if extents_dict is not None:\n",
    "            key = entry_index if entry_index is not None else entry_title\n",
    "            extents_dict[key] = extent    \n",
    "        if webmap_from_json:\n",
    "            try:\n",
    "                thumbnail_path, final_webmap_json, print_service_responses = create_webmap_thumbnail(webmap_json=webmap_from_json, default_thumbnail_path=default_thumbnail_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing webmap {entry_title} ({webmap_id}): {e}\")\n",
    "                invalid_webmap = True\n",
    "        if webmap_id and not invalid_webmap:\n",
    "            try:\n",
    "                main_stage_content = Map(webmap_id)\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating Map object for {entry_title} ({webmap_id}): {e}\")\n",
    "                invalid_webmap = True\n",
    "    elif media_type == \"webpage\":\n",
    "        webpage_url = media_info.get(\"webpage\", {}).get(\"url\")\n",
    "        if webpage_url:\n",
    "            main_stage_content = Embed(webpage_url)\n",
    "    elif media_type == \"image\":\n",
    "        image_url = media_info.get(\"image\", {}).get(\"url\")\n",
    "        if image_url:\n",
    "            main_stage_content = Image(image_url)\n",
    "            thumbnail_path = create_image_thumbnail(image_url=image_url, default_thumbnail_path=default_thumbnail_path)\n",
    "\n",
    "    if not thumbnail_path:\n",
    "        thumbnail_path = create_image_thumbnail(image_url=default_thumbnail_path, default_thumbnail_path=default_thumbnail_path)\n",
    "\n",
    "    return entry_title, main_stage_content, thumbnail_path, invalid_webmap, final_webmap_json, print_service_responses\n",
    "\n",
    "def build_webmap_from_json(gis, media):\n",
    "    \"\"\"\n",
    "    Build a minimal webmap JSON for the print service from a storymap entry's media property,\n",
    "    using the basemap from the referenced webmap item if available.\n",
    "    \"\"\"\n",
    "    # Default basemap (fallback)\n",
    "    topo_basemap = {\n",
    "        \"baseMapLayers\": [{\n",
    "            \"id\": \"World_Topo_Map\",\n",
    "            \"layerType\": \"ArcGISTiledMapServiceLayer\",\n",
    "            \"opacity\": 1,\n",
    "            \"visibility\": True,\n",
    "            \"url\": \"https://services.arcgisonline.com/ArcGIS/rest/services/World_Topo_Map/MapServer\"\n",
    "        }],\n",
    "        \"title\": \"Topographic\"\n",
    "    }\n",
    "\n",
    "    imagery_basemap = {\n",
    "        \"baseMapLayers\": [{\n",
    "            \"id\": \"World_Imagery\",\n",
    "            \"layerType\": \"ArcGISTiledMapServiceLayer\",\n",
    "            \"opacity\": 1,\n",
    "            \"visibility\": True,\n",
    "            \"url\": \"https://services.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer\"\n",
    "        }],\n",
    "        \"title\": \"Imagery\"\n",
    "    }\n",
    "\n",
    "    baseMap = topo_basemap\n",
    "\n",
    "    # Try to get basemap from the referenced webmap item\n",
    "    if \"webmap\" in media and \"id\" in media[\"webmap\"]:\n",
    "        try:\n",
    "            webmap_item = gis.content.get(media[\"webmap\"][\"id\"])\n",
    "            wm_data = webmap_item.get_data()\n",
    "            if \"baseMap\" in wm_data and \"baseMapLayers\" in wm_data[\"baseMap\"]:\n",
    "                # Only keep required fields for each basemap layer\n",
    "                baseMapLayers = []\n",
    "                for lyr in wm_data[\"baseMap\"][\"baseMapLayers\"]:\n",
    "                    baseMapLayers.append({\n",
    "                        \"id\": lyr.get(\"id\", \"basemap\"),\n",
    "                        \"layerType\": lyr.get(\"layerType\", \"ArcGISTiledMapServiceLayer\"),\n",
    "                        \"opacity\": lyr.get(\"opacity\", 1),\n",
    "                        \"visibility\": lyr.get(\"visibility\", True),\n",
    "                        \"url\": lyr.get(\"url\")\n",
    "                    })\n",
    "                baseMap = {\n",
    "                    \"baseMapLayers\": baseMapLayers,\n",
    "                    \"title\": wm_data[\"baseMap\"].get(\"title\", \"Basemap\")\n",
    "                }\n",
    "        except Exception as e:\n",
    "            print(f\"Could not fetch basemap from webmap item: {e}. Using fallback basemap.\")\n",
    "\n",
    "    # Get extent and spatial reference from the referenced webmap\n",
    "    extent = None\n",
    "    spatialRef = {\"wkid\": 102100}\n",
    "    if \"webmap\" in media:\n",
    "        if \"spatialReference\" in media[\"webmap\"]:\n",
    "            spatialRef = media[\"webmap\"][\"spatialReference\"]\n",
    "        if \"extent\" in media[\"webmap\"]:\n",
    "            # Clamp the max extent to the spatial reference's max extent\n",
    "            media[\"webmap\"][\"extent\"] = clamp_extent_to_spatial_reference(media[\"webmap\"][\"extent\"], spatialRef)\n",
    "            extent = media[\"webmap\"][\"extent\"]\n",
    "    # Ensure extent is present and valid\n",
    "    if not extent:\n",
    "        extent = {\n",
    "            \"xmin\": -20037508.342789244,\n",
    "            \"ymin\": -20037508.342789244,\n",
    "            \"xmax\": 20037508.342789244,\n",
    "            \"ymax\": 20037508.342789244,\n",
    "            \"spatialReference\": spatialRef\n",
    "        }\n",
    "    mapOptions = {\"extent\": extent}\n",
    "\n",
    "    # Get layers from the webmap\n",
    "    operationalLayers = []\n",
    "    if \"webmap\" in media and \"layers\" in media[\"webmap\"]:\n",
    "        layers = media[\"webmap\"][\"layers\"]\n",
    "        if layers:\n",
    "            for lyr in layers:\n",
    "                # Try to get URL from referenced webmap item\n",
    "                layer_url = lyr.get(\"url\")\n",
    "                if not layer_url and \"id\" in lyr and \"id\" in media[\"webmap\"]:\n",
    "                    try:\n",
    "                        webmap_item = gis.content.get(media[\"webmap\"][\"id\"])\n",
    "                        wm_data = webmap_item.get_data()\n",
    "                        for op_lyr in wm_data.get(\"operationalLayers\", []):\n",
    "                            if op_lyr.get(\"id\") == lyr[\"id\"]:\n",
    "                                layer_url = op_lyr.get(\"url\")\n",
    "                                break\n",
    "                    except Exception as e:\n",
    "                        print(f\"Could not fetch webmap item for layer URL lookup: {e}\")\n",
    "                if layer_url:\n",
    "                    operationalLayers.append({\n",
    "                        \"id\": lyr.get(\"id\", \"layer\"),\n",
    "                        \"layerType\": lyr.get(\"layerType\", \"ArcGISFeatureLayer\"),\n",
    "                        \"url\": layer_url,\n",
    "                        \"visibility\": lyr.get(\"visibility\", True),\n",
    "                        \"opacity\": lyr.get(\"opacity\", 1)\n",
    "                    })\n",
    "\n",
    "    # Export options for print service\n",
    "    export_options = {\"outputSize\": [800, 600], \"dpi\": 96}\n",
    "\n",
    "    webmap_json = {\n",
    "        \"baseMap\": baseMap,\n",
    "        \"operationalLayers\": operationalLayers,\n",
    "        \"spatialReference\": spatialRef,\n",
    "        \"mapOptions\": mapOptions,\n",
    "        \"exportOptions\": export_options   \n",
    "    }    \n",
    "    \n",
    "    # Invert the drawing order of operational layers\n",
    "    if \"operationalLayers\" in webmap_json:\n",
    "        webmap_json[\"operationalLayers\"] = list(reversed(webmap_json[\"operationalLayers\"]))\n",
    "\n",
    "    return webmap_json\n",
    "\n",
    "def clamp_extent_to_spatial_reference(extent, spatial_reference):\n",
    "    \"\"\"\n",
    "    Clamp extent values to the valid range for the given spatial reference.\n",
    "    Uses a lookup table for common WKIDs, otherwise tries pyproj for bounds.\n",
    "    Installs pyproj if needed (conda preferred, pip fallback).\n",
    "    \"\"\"\n",
    "    max_extents = {\n",
    "        102100: {\"xmin\": -20037508.342789244, \"ymin\": -20037508.342789244, \"xmax\": 20037508.342789244, \"ymax\": 20037508.342789244},\n",
    "        3857:   {\"xmin\": -20037508.342789244, \"ymin\": -20037508.342789244, \"xmax\": 20037508.342789244, \"ymax\": 20037508.342789244},\n",
    "        4326:   {\"xmin\": -180, \"ymin\": -90, \"xmax\": 180, \"ymax\": 90},  # WGS84\n",
    "        # Add more WKIDs as needed\n",
    "    }\n",
    "\n",
    "    wkid = None\n",
    "    wkt = None\n",
    "    if isinstance(spatial_reference, dict):\n",
    "        wkid = spatial_reference.get(\"wkid\")\n",
    "        wkt = spatial_reference.get(\"wkt\")\n",
    "    elif isinstance(spatial_reference, int):\n",
    "        wkid = spatial_reference\n",
    "    if wkid in max_extents:\n",
    "        max_extent = max_extents[wkid]\n",
    "    else:\n",
    "        print(f\"WKID {wkid} not found in lookup table. Attempting to use pyproj to get bounds...\")\n",
    "        # Try to import pyproj, install if missing\n",
    "        try:\n",
    "            from pyproj import CRS\n",
    "        except ImportError:\n",
    "            print(\"pyproj not found. Attempting to install pyproj with conda...\")\n",
    "            try:\n",
    "                subprocess.check_call([sys.executable, \"-m\", \"conda\", \"install\", \"-y\", \"pyproj\"])\n",
    "            except Exception:\n",
    "                print(\"conda install failed or not available. Trying pip install...\")\n",
    "                subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"pyproj\"])\n",
    "            from pyproj import CRS\n",
    "        # Now try to get bounds\n",
    "        max_extent = get_max_extent_from_wkid(wkid)\n",
    "        if not max_extent:\n",
    "            print(f\"Could not determine bounds for WKID {wkid}. Extent not clamped.\")\n",
    "            return extent\n",
    "\n",
    "    clamped_extent = {\n",
    "        \"xmin\": max(min(extent.get(\"xmin\", max_extent[\"xmin\"]), max_extent[\"xmax\"]), max_extent[\"xmin\"]),\n",
    "        \"ymin\": max(min(extent.get(\"ymin\", max_extent[\"ymin\"]), max_extent[\"ymax\"]), max_extent[\"ymin\"]),\n",
    "        \"xmax\": max(min(extent.get(\"xmax\", max_extent[\"xmax\"]), max_extent[\"xmax\"]), max_extent[\"xmin\"]),\n",
    "        \"ymax\": max(min(extent.get(\"ymax\", max_extent[\"ymax\"]), max_extent[\"ymax\"]), max_extent[\"ymin\"]),\n",
    "        \"spatialReference\": spatial_reference\n",
    "    }\n",
    "    return clamped_extent\n",
    "\n",
    "def get_max_extent_from_wkid(wkid):\n",
    "    try:\n",
    "        from pyproj import CRS\n",
    "        crs = CRS.from_epsg(wkid)\n",
    "        bounds = crs.area_of_use.bounds  # (west, south, east, north)\n",
    "        return {\n",
    "            \"xmin\": bounds[0],\n",
    "            \"ymin\": bounds[1],\n",
    "            \"xmax\": bounds[2],\n",
    "            \"ymax\": bounds[3]\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Could not get bounds for WKID {wkid}: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_image_thumbnail(image_url, default_thumbnail_path):\n",
    "    try:\n",
    "        response = requests.get(image_url)\n",
    "        img = PILImage.open(BytesIO(response.content))\n",
    "        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.png')\n",
    "        img.thumbnail((800, 600))\n",
    "        img.save(temp_file.name)\n",
    "        return temp_file.name\n",
    "    except Exception:\n",
    "        print(\"Thumbnail download failed; using default.\")\n",
    "        img = PILImage.open(BytesIO(requests.get(default_thumbnail_path).content))\n",
    "        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.png')\n",
    "        img.thumbnail((800, 600))\n",
    "        img.save(temp_file.name)\n",
    "        return temp_file.name\n",
    "\n",
    "def remove_failed_service(webmap_json, failed_url):\n",
    "    # Remove from operationalLayers\n",
    "    if 'operationalLayers' in webmap_json:\n",
    "        webmap_json['operationalLayers'] = [\n",
    "            lyr for lyr in webmap_json['operationalLayers']\n",
    "            if not lyr.get('url', '').startswith(failed_url)\n",
    "        ]\n",
    "    # Remove from baseMapLayers\n",
    "    if 'baseMap' in webmap_json and 'baseMapLayers' in webmap_json['baseMap']:\n",
    "        webmap_json['baseMap']['baseMapLayers'] = [\n",
    "            lyr for lyr in webmap_json['baseMap']['baseMapLayers']\n",
    "            if not lyr.get('url', '').startswith(failed_url)\n",
    "        ]\n",
    "    return webmap_json\n",
    "\n",
    "# For downloads, use in-memory BytesIO where possible\n",
    "def create_webmap_thumbnail(webmap_json, default_thumbnail_path):\n",
    "    url = \"https://utility.arcgisonline.com/arcgis/rest/services/Utilities/PrintingTools/GPServer/Export%20Web%20Map%20Task/execute\"\n",
    "    #webmap_json = webmap_item.get_data()\n",
    "    webmap_json = webmap_json if isinstance(webmap_json, dict) else json.loads(webmap_json)\n",
    "    webmap_json_copy = deepcopy(webmap_json)\n",
    "    tried_urls = set()\n",
    "    max_attempts = 10  # Prevent infinite loops\n",
    "\n",
    "    # List to capture all print service responses\n",
    "    print_service_responses = []\n",
    "    final_webmap_json = None\n",
    "\n",
    "    # Ensure exportOptions is set\n",
    "    if 'exportOptions' not in webmap_json_copy:\n",
    "        webmap_json_copy['exportOptions'] = {\n",
    "            \"outputSize\": [800, 600],\n",
    "            \"dpi\": 96\n",
    "        }\n",
    "    # Ensure mapOptions/extent is set\n",
    "    if 'mapOptions' not in webmap_json_copy:\n",
    "        webmap_json_copy['mapOptions'] = {}\n",
    "    if 'extent' not in webmap_json_copy['mapOptions']:\n",
    "        webmap_json_copy['mapOptions']['extent'] = webmap_json.get('mapOptions', {}).get('extent', webmap_json.get('initialState', {}).get('viewpoint', {}).get('targetGeometry'))\n",
    "\n",
    "    for attempt in range(max_attempts):\n",
    "        params = {\n",
    "            \"f\": \"json\",\n",
    "            \"Web_Map_as_JSON\": json.dumps(webmap_json_copy),\n",
    "            \"Format\": \"PNG32\",\n",
    "            \"Layout_Template\": \"MAP_ONLY\"\n",
    "        }\n",
    "        \n",
    "        # Capture the final json sent to the print service for troubleshoorting\n",
    "        final_webmap_json = deepcopy(webmap_json_copy)\n",
    "        \n",
    "        response = requests.post(url, data=params)\n",
    "        result = response.json()\n",
    "\n",
    "        # Capture the print service response for troubleshooting\n",
    "        print_service_responses.append({\n",
    "            \"attempt\": attempt + 1,\n",
    "            \"params\": params,\n",
    "            \"status_code\": response.status_code,\n",
    "            \"result\": result\n",
    "        })\n",
    "\n",
    "        if 'results' in result:\n",
    "            image_url = result['results'][0]['value']['url']\n",
    "            img_response = requests.get(image_url)\n",
    "            if img_response.status_code == 200:\n",
    "                temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.png')\n",
    "                temp_file.write(img_response.content)\n",
    "                temp_file.close()\n",
    "                img = PILImage.open(temp_file.name)\n",
    "                is_blank = is_blank_image(temp_file.name)\n",
    "                if is_blank:\n",
    "                    print(\"Generated thumbnail is blank; scaling extent and retrying.\")\n",
    "                    # Try to scale the extent if possible\n",
    "                    extent = webmap_json_copy.get('mapOptions', {}).get('extent')\n",
    "                    # if extent:\n",
    "                    #     new_extent = scale_extent(extent, scale_factor=1.1)\n",
    "                    #     webmap_json_copy['mapOptions']['extent'] = new_extent\n",
    "                    #     webmap_json_copy['extent'] = new_extent\n",
    "                    #     continue  # Retry with new extent\n",
    "                    # else:\n",
    "                    if not extent:\n",
    "                        print(\"No extent found to scale; using default image.\")\n",
    "                        default_path = create_image_thumbnail(image_url=default_thumbnail_path, default_thumbnail_path=default_thumbnail_path)\n",
    "                        return default_path, print_service_responses, final_webmap_json\n",
    "                return temp_file.name, print_service_responses, final_webmap_json\n",
    "            else:\n",
    "                break  # No valid image, break and use default\n",
    "\n",
    "        elif 'error' in result and 'details' in result['error']:\n",
    "            # Try to extract the failed service URL\n",
    "            failed_layer_detail = result['error']['details'][0]\n",
    "            if ' at ' in failed_layer_detail:\n",
    "                failed_service_url = failed_layer_detail.split(' at ')[-1]\n",
    "                if failed_service_url in tried_urls:\n",
    "                    break  # Prevent infinite loop if same URL keeps failing\n",
    "                tried_urls.add(failed_service_url)\n",
    "                webmap_json_copy = remove_failed_service(webmap_json_copy, failed_service_url)\n",
    "                continue  # Try again with the updated JSON\n",
    "            else:\n",
    "                break  # Can't parse the failed URL, break and use default\n",
    "        else:\n",
    "            break  # No results and no error details, break and use default\n",
    "\n",
    "    # If we reach here, fallback to default\n",
    "    print(\"Thumbnail download failed; using default.\")\n",
    "    default_path = create_image_thumbnail(image_url=default_thumbnail_path, default_thumbnail_path=default_thumbnail_path)\n",
    "    return default_path, print_service_responses, final_webmap_json\n",
    "\n",
    "def is_blank_image(image_path, threshold=5):\n",
    "    img = PILImage.open(image_path).convert('L')\n",
    "    pixels = list(img.getdata())\n",
    "    unique_values = set(pixels)\n",
    "    # If only 1 or 2 unique values (e.g., all black, all white, or half black/half white), treat as blank\n",
    "    if len(unique_values) <= 2:\n",
    "        return True\n",
    "    stat = ImageStat.Stat(img)\n",
    "    return stat.stddev[0] < threshold  # fallback for nearly-uniform images\n",
    "\n",
    "def scale_extent(extent, scale_factor=1.1):\n",
    "    \"\"\"\n",
    "    Scales the extent by the given scale_factor (e.g., 1.1 for 10% larger).\n",
    "    Extent should be a dict with xmin, ymin, xmax, ymax keys.\n",
    "    \"\"\"\n",
    "    if not extent:\n",
    "        return extent\n",
    "    xmin, ymin, xmax, ymax = extent['xmin'], extent['ymin'], extent['xmax'], extent['ymax']\n",
    "    x_center = (xmin + xmax) / 2\n",
    "    y_center = (ymin + ymax) / 2\n",
    "    width = (xmax - xmin) * scale_factor\n",
    "    height = (ymax - ymin) * scale_factor\n",
    "    new_xmin = x_center - width / 2\n",
    "    new_xmax = x_center + width / 2\n",
    "    new_ymin = y_center - height / 2\n",
    "    new_ymax = y_center + height / 2\n",
    "    return {'xmin': new_xmin, 'ymin': new_ymin, 'xmax': new_xmax, 'ymax': new_ymax, 'spatialReference': extent.get('spatialReference', {'wkid': 102100})}\n",
    "\n",
    "\n",
    "def build_and_save_storymap(entry, entry_index, entry_title, main_stage_content, new_theme, thumbnail_path, default_thumbnail_path):\n",
    "    media_info = entry.get(\"media\", {})\n",
    "    media_type = media_info.get(\"type\")\n",
    "    main_stage_content = main_stage_content\n",
    "    story = StoryMap()\n",
    "    story.theme(new_theme)\n",
    "    sidecar = Sidecar(style=\"docked-panel\")\n",
    "    story.add(sidecar)\n",
    "\n",
    "    description_html = entry.get(\"description\", \"\")\n",
    "    # Parse HTML and convert to StoryMap nodes\n",
    "    content_nodes, content_image_metadata = convert_html_elements_to_storymap_node(parse_root_elements(description_html))\n",
    "    # Add main stage content and text content to sidecar\n",
    "    sidecar.add_slide(contents=content_nodes, media=main_stage_content)\n",
    "\n",
    "    # Assign metadata to each image in contents\n",
    "    for img, caption, alt, link in content_image_metadata:\n",
    "        try:\n",
    "            img.caption = caption\n",
    "            img.alt_text = alt\n",
    "            img.link = link\n",
    "        except Exception as e:\n",
    "            print(f\"Error setting image metadata: {e}\")\n",
    "\n",
    "    # Set media properties\n",
    "    if isinstance(main_stage_content, Map):\n",
    "        # Set webmap properties. Map must be added to the story before setting viewpoint\n",
    "        if media_type == \"webmap\":\n",
    "            # Set the extent for the map stage\n",
    "            extent_json = media_info.get('webmap', {}).get('extent')\n",
    "            if extent_json:\n",
    "                main_stage_content.set_viewpoint(extent=extent_json)  # Extent dict per docs\n",
    "            # Set layer visibility \n",
    "            old_layers = media_info.get('webmap', {}).get('layers', [])\n",
    "            if old_layers:\n",
    "                if hasattr(main_stage_content, \"map_layers\"):\n",
    "                    for new_lyr in main_stage_content.map_layers:\n",
    "                        for old_lyr in old_layers:\n",
    "                            if new_lyr['id'] == old_lyr['id']:\n",
    "                                new_lyr['visible'] = old_lyr['visibility']\n",
    "            elif \"operationalLayers\" in media_info.get('webmap', {}):\n",
    "                old_layers = media_info.get('webmap', {}).get('operationalLayers', [])\n",
    "                if hasattr(main_stage_content, \"map_layers\"):\n",
    "                    for new_lyr in main_stage_content.map_layers:\n",
    "                        for old_lyr in old_layers:\n",
    "                            if 'id' in new_lyr and 'id' in old_lyr and new_lyr['id'] == old_lyr['id']:\n",
    "                                new_lyr['visible'] = old_lyr['visibility']\n",
    "\n",
    "    if isinstance(main_stage_content, Image):\n",
    "        if caption:\n",
    "            main_stage_content.caption = media_info.get(\"image\", {}).get(\"caption\", \"\")\n",
    "        if alt:\n",
    "            main_stage_content.alt_text = media_info.get(\"image\", {}).get(\"alt\", \"\")\n",
    "        if link:\n",
    "            main_stage_content.link = media_info.get(\"image\", {}).get(\"link\", \"\")\n",
    "        # if display: # https://developers.arcgis.com/python/latest/api-reference/arcgis.apps.storymap.html#arcgis.apps.storymap.story_content.Image.display\n",
    "        #    main_stage_content.display = display\n",
    "        # if properties:\n",
    "        #    main_stage_content.properties = properties\n",
    "\n",
    "    # Set cover properties\n",
    "    cover_properties = story.content_list[0]\n",
    "    cover_properties.title = entry_title\n",
    "    cover_properties.byline = \"\"\n",
    "    cover_properties.date = \"none\"\n",
    "    if not thumbnail_path or not os.path.isfile(thumbnail_path):\n",
    "        thumbnail_path = default_thumbnail_path\n",
    "    cover_properties.media = Image(thumbnail_path) \n",
    "\n",
    "    # Hide cover\n",
    "    for k, v in story.properties['nodes'].items():\n",
    "        if v['type'] == 'storycover':\n",
    "            v['config'] = {'isHidden': 'true'}\n",
    "\n",
    "    # Save and publish\n",
    "    story.save(title=entry_title, tags=[\"auto-created\"], publish=True)\n",
    "    if hasattr(story, '_item'):\n",
    "        published_story_item = story._item\n",
    "        published_story_item.update(thumbnail=thumbnail_path)\n",
    "        published_story_item_url = \"https://storymaps.arcgis.com/stories/\" + published_story_item.id\n",
    "        print(f\"{published_story_item_url} '{entry_title}' is staged for publishing. Click the link to complete.\")\n",
    "        return story, published_story_item\n",
    "    else:\n",
    "        print(\"Could not find item for story:\", story.title)\n",
    "        return story, None\n",
    "\n",
    "def build_collection(classic_item, published_storymap_items, thumbnail_paths, classic_story_type, new_theme):\n",
    "    collection = Collection()\n",
    "    collection_title = classic_item.title\n",
    "    for i, story in enumerate(published_storymap_items):\n",
    "        try:\n",
    "            if Item(gis=gis, itemid=story.itemid).get_data():\n",
    "                collection.add(item=story, title=story.title, thumbnail=thumbnail_paths[i])\n",
    "            else:\n",
    "                print(f\"There was a problem publishing '{story.title}'. Open the link {story.url}and try again.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error adding story to collection: {e}\")\n",
    "    # Set collection properties\n",
    "    collection.content[0].title = collection_title\n",
    "    collection.content[0].byline = \"\"\n",
    "    collection.theme(new_theme)\n",
    "    collection.content[1].type = classic_story_type\n",
    "    # Set the Collection thumbnail to be the same as the classic story\n",
    "    classic_thumbnail_path = download_thumbnail(Item(gis=gis, itemid=classic_item.itemid), default_thumbnail_path, gis)\n",
    "    collection.content[1].media = Image(path=classic_thumbnail_path)\n",
    "    collection.save(title=collection_title, tags=[\"auto-created\"], publish=True)\n",
    "    return collection_title, collection._url\n",
    "\n",
    "######################################################\n",
    "\n",
    "# Instead of using threading.Thread and stopevent, update progress directly after each major step\n",
    "def update_progress(progressbar, value, description=''):\n",
    "    progressbar.value = value\n",
    "    progressbar.description = description if description else progressbar.description\n",
    "\n",
    "def color_to_hex(color_value):\n",
    "    color_value = color_value.strip()\n",
    "    # Check for rgb() format\n",
    "    rgb_match = re.match(r'rgb-?(\\d+)-?(\\d+)-?(\\d+)', color_value, re.IGNORECASE)\n",
    "    if rgb_match:\n",
    "        r, g, b = map(int, rgb_match.groups())\n",
    "        return '{:02X}{:02X}{:02X}'.format(r, g, b)\n",
    "    # Check for named color\n",
    "    try:\n",
    "        return mcolors.CSS4_COLORS[color_value.lower()].upper()\n",
    "    except ValueError:\n",
    "        pass\n",
    "    # Already hex\n",
    "    if color_value.startswith('#') and len(color_value) == 7:\n",
    "        return color_value.upper()\n",
    "    return None\n",
    "\n",
    "def convert_color_style_to_class(tag):\n",
    "    # Check if tag has 'style' attribute with color\n",
    "    style = tag.get('style', '')\n",
    "    # Regex to find color property (hex, rgb, named colors)\n",
    "    match = re.search(r'color\\s*:\\s*([^;]+)', style, re.IGNORECASE)\n",
    "    if match:\n",
    "        color_value = match.group(1).strip()\n",
    "        # Convert hex (#XXXXXX) to class name, removing #\n",
    "        if color_value.startswith('#'):\n",
    "            class_color = f\"sm-text-color-{color_value[1:].upper()}\"\n",
    "        else:\n",
    "            # For rgb or named color, sanitize usable string (replace spaces/paren)\n",
    "            sanitized = re.sub(r'[\\s\\(\\)]', '', color_value).replace(',', '-')\n",
    "            hex_color = color_to_hex(sanitized)\n",
    "            class_color = f\"sm-text-color-{hex_color}\"\n",
    "        # Remove color from style attribute\n",
    "        new_style = re.sub(r'color\\s*:\\s*[^;]+;?', '', style, flags=re.IGNORECASE).strip()\n",
    "        if new_style:\n",
    "            tag['style'] = new_style\n",
    "        else:\n",
    "            del tag['style']\n",
    "        # Add or append class attribute\n",
    "        if 'class' in tag.attrs:\n",
    "            tag['class'].append(class_color)\n",
    "        else:\n",
    "            tag['class'] = [class_color]\n",
    "\n",
    "def process_html_colors_preserve_html(html_text):\n",
    "    soup = BeautifulSoup(html_text, \"html.parser\")\n",
    "    # Iterate over tags that can have styles: div, span, strong, em, p, etc.\n",
    "    for tag in soup.find_all(True):\n",
    "        convert_color_style_to_class(tag)\n",
    "    return str(soup)\n",
    "\n",
    "def convert_element_to_storymap_object(el):\n",
    "    img_tag = el.find('img')\n",
    "    if img_tag:\n",
    "        src = img_tag.get(\"src\")\n",
    "        # Upgrade http to https if needed\n",
    "        if src and src.startswith(\"http://\"):\n",
    "            src = \"https://\" + src[len(\"http://\"):]\n",
    "        alt = img_tag.get(\"alt\", \"\")\n",
    "        link = \"\" # TO DO handle occasions when image is intended to launch a link\n",
    "        # Find figcaption in parent figure or div\n",
    "        figcaption = \"\"\n",
    "        # print(\"img_tag:\", img_tag)\n",
    "        parent_figure = img_tag.find_parent(\"figure\")\n",
    "        # print(\"parent_figure:\", parent_figure)\n",
    "        if parent_figure:\n",
    "            caption_tag = parent_figure.find(\"figcaption\")\n",
    "            # print(\"caption_tag:\", caption_tag)\n",
    "            if caption_tag:\n",
    "                figcaption = caption_tag.get_text(strip=True)\n",
    "        else:\n",
    "            # Try to find figcaption in the parent div\n",
    "            parent_div = img_tag.find_parent(\"div\")\n",
    "            # print(\"parent_div:\", parent_div)\n",
    "            if parent_div:\n",
    "                caption_tag = parent_div.find(\"figcaption\")\n",
    "                # print(\"caption_tag (div):\", caption_tag)\n",
    "                if caption_tag:\n",
    "                    figcaption = caption_tag.get_text(strip=True)\n",
    "        # print(\"Extracted figcaption:\", figcaption, type(figcaption))\n",
    "        img = Image(path=src)\n",
    "        #img.link = link\n",
    "        #img.image = src\n",
    "        return img, figcaption, alt, link\n",
    "\n",
    "    tag_name = el.name\n",
    "    if tag_name == \"p\": # or tag_name in [\"span\", \"strong\", \"em\", \"div\"]:\n",
    "        # Extract inner HTML preserving inline styles\n",
    "        inner_html = ''.join(str(c) for c in el.contents)\n",
    "        processed_html = process_html_colors_preserve_html(inner_html)\n",
    "        return Text(text=processed_html, style=TextStyles.PARAGRAPH)\n",
    "\n",
    "    elif tag_name == \"video\":\n",
    "        src = el.get(\"src\")\n",
    "        alt = el.get(\"alt\", \"\")\n",
    "        vid = Video(path=src)\n",
    "        vid.alt_text = alt\n",
    "        vid.caption = \"\" # TO DO try to find Classic stories that have Videos with captions\n",
    "        vid.video = src # Assign video property. TO DO fix this for hosted videos\n",
    "        return vid\n",
    "    \n",
    "    elif tag_name == \"audio\":\n",
    "        src = el.get(\"src\")\n",
    "        alt = el.get(\"alt\", \"\")\n",
    "        aud = Audio(path=src)\n",
    "        aud.alt_text = alt\n",
    "        aud.caption = \"\" # TO DO try to find Classic stories that have Audio with captions\n",
    "        aud.audio = src # Assign Audio property. TO DO fix this for hosted videos\n",
    "        return aud\n",
    "    \n",
    "    elif tag_name == \"iframe\" or tag_name == \"embed\":\n",
    "        src = el.get(\"src\") or el.get(\"data-src\")\n",
    "        alt = el.get(\"alt\", \"\")\n",
    "        if src:\n",
    "            emb = Embed(path=src)\n",
    "            emb.alt_text = alt\n",
    "            emb.caption = \"\" # TO DO try to find Classic stories that have Embeds with captions\n",
    "            emb.link = src\n",
    "        return emb\n",
    "\n",
    "    elif tag_name == \"map\":\n",
    "        src = el.get(\"src\")\n",
    "        alt = el.get(\"alt\", \"\")\n",
    "        extent = \"\" #TO DO get extent\n",
    "        layers = \"\" # TO DO get map layers\n",
    "        mp = Map(item=\"\")\n",
    "        mp.alt_text = alt\n",
    "        mp.caption = \"\" # TO DO try to find Classic stories that have Maps in Sidecar panel with captions\n",
    "        mp.map = src\n",
    "        mp.map_layers = layers \n",
    "        mp.set_viewpoint = extent\n",
    "        return aud\n",
    "    \n",
    "    else:\n",
    "        # Fallback for unsupported or unknown types - treat as text\n",
    "        inner_html = ''.join(str(c) for c in el.contents)\n",
    "        processed_html = process_html_colors_preserve_html(inner_html)\n",
    "        return Text(text=processed_html, style=TextStyles.PARAGRAPH)\n",
    "\n",
    "def parse_root_elements(html_snippet):\n",
    "    soup = BeautifulSoup(html_snippet, \"html.parser\")\n",
    "    html_elements = []\n",
    "    for child in soup.contents:\n",
    "        if not getattr(child, 'name', None):\n",
    "            continue\n",
    "\n",
    "        # If this is a <figure> with an <img>, add the whole figure\n",
    "        if child.name == \"figure\" and child.find('img'):\n",
    "            html_elements.append(child)\n",
    "            continue\n",
    "\n",
    "        # Check if the parent itself is meaningful\n",
    "        has_text = child.get_text(strip=True) != \"\"\n",
    "        has_img = child.find('img') is not None\n",
    "        has_video = child.find('video') is not None\n",
    "        has_audio = child.find('audio') is not None\n",
    "        has_iframe = child.find('iframe') is not None\n",
    "        has_embed = child.find('embed') is not None\n",
    "        has_map = child.find('map') is not None\n",
    "        is_meaningful = has_text or has_img or has_video or has_audio or has_iframe or has_embed or has_map\n",
    "\n",
    "        # Check for meaningful children\n",
    "        meaningful_children = []\n",
    "        for c in child.children:\n",
    "            if not getattr(c, 'name', None):\n",
    "                continue\n",
    "            c_has_text = c.get_text(strip=True) != \"\"\n",
    "            c_has_img = c.find('img') is not None\n",
    "            c_has_video = c.find('video') is not None\n",
    "            c_has_audio = c.find('audio') is not None\n",
    "            c_has_iframe = c.find('iframe') is not None\n",
    "            c_has_embed = c.find('embed') is not None\n",
    "            c_has_map = c.find('map') is not None\n",
    "            if c_has_text or c_has_img or c_has_video or c_has_audio or c_has_iframe or c_has_embed or c_has_map:\n",
    "                meaningful_children.append(c)\n",
    "\n",
    "        # If there are meaningful children, add them\n",
    "        if meaningful_children:\n",
    "            html_elements.extend(meaningful_children)\n",
    "            # Optionally, if the parent is also meaningful and not just a container, add it too\n",
    "            # If you want to avoid duplicates, only add children\n",
    "            continue\n",
    "\n",
    "        # If no meaningful children, but parent is meaningful, add parent\n",
    "        if is_meaningful:\n",
    "            html_elements.append(child)\n",
    "\n",
    "    return html_elements\n",
    "\n",
    "\n",
    "# def parse_nested_elements(html_snippet):\n",
    "#     soup = BeautifulSoup(html_snippet, \"html.parser\")\n",
    "#     soup_list = [child for child in soup.contents if getattr(child, 'name', None)]\n",
    "#     html_elements = []\n",
    "#     for element in soup_list:\n",
    "#         for c in element:\n",
    "#             if getattr(c, 'name', None):\n",
    "#                 html_elements.append(c)\n",
    "#     return html_elements\n",
    "\n",
    "def convert_html_elements_to_storymap_node(html_elements):\n",
    "    content_nodes = []\n",
    "    image_metadata = []  # To store (img, caption, alt, link) tuples\n",
    "    for el in html_elements:\n",
    "        node = convert_element_to_storymap_object(el)\n",
    "        if isinstance(node, tuple):\n",
    "            img, caption, alt, link = node\n",
    "            content_nodes.append(img)\n",
    "            image_metadata.append((img, caption, alt, link))\n",
    "        elif node:\n",
    "            content_nodes.append(node)\n",
    "    return content_nodes, image_metadata\n",
    "\n",
    "# def get_thumbnail_path(path):\n",
    "#     try:\n",
    "#         if path and isinstance(path, str):\n",
    "#             # Try local file check, otherwise use default\n",
    "#             with open(path, 'rb'):\n",
    "#                 return path\n",
    "#     except Exception:\n",
    "#         pass\n",
    "#     # Use default thumbnail path hosted online\n",
    "#     return default_thumbnail_path\n",
    "    \n",
    "# For downloads, use in-memory BytesIO where possible\n",
    "def download_thumbnail(webmap_item, default_thumbnail_path, gis=None):\n",
    "    try:\n",
    "        url = f\"{webmap_item._portal.resturl}content/items/{webmap_item.id}/info/{webmap_item.thumbnail}\"\n",
    "        token = gis._con.token if gis else None\n",
    "        params = {'token': token} if token else {}\n",
    "        response = requests.get(url, params=params)\n",
    "        img = PILImage.open(BytesIO(response.content))\n",
    "        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.png')\n",
    "        img.save(temp_file.name)\n",
    "        return temp_file.name\n",
    "    except Exception:\n",
    "        print(\"Thumbnail download failed; using default.\")\n",
    "        url = default_thumbnail_path\n",
    "        response = requests.get(url)\n",
    "        img = PILImage.open(BytesIO(response.content))\n",
    "        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.png')\n",
    "        img.save(temp_file.name)\n",
    "        return temp_file.name\n",
    "\n",
    "#def ensure_local_thumbnail(thumbnail_path, local_filename=\"default_storymap_thumbnail.png\"):\n",
    "#    # If it's already a local file, just return it\n",
    "#    if thumbnail_path: # and os.path.isfile(thumbnail_path):\n",
    "#        return thumbnail_path\n",
    "#    # Otherwise, download it\n",
    "#    response = requests.get(thumbnail_path)\n",
    "#    with open(local_filename, \"wb\") as f:\n",
    "#        f.write(response.content)\n",
    "#    return local_filename\n",
    "\n",
    "#def create_image_thumbnail(image_url, thumbnail_path):\n",
    "#    response = requests.get(image_url)\n",
    "#    img = PILImage.open(BytesIO(response.content))\n",
    "#    img.thumbnail((800, 600))\n",
    "#    img.save(thumbnail_path)\n",
    "#    return thumbnail_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ArcGIS API for Python version: 2.4.1.3\n",
      "Successfully logged in as: dasbury_storymaps (role: org_admin userType: GISProfessionalAdvUT)\n"
     ]
    }
   ],
   "source": [
    "# Print the version of the arcgis module\n",
    "print(f\"Running ArcGIS API for Python version: {arcgis.__version__}\")\n",
    "agoNotebook = False\n",
    "# Define the GIS\n",
    "if agoNotebook == False:\n",
    "    try:\n",
    "        import keyring\n",
    "        service_name = \"system\" # Use the default local credential store\n",
    "        success = False # Set initial state\n",
    "\n",
    "        # Ask for the username\n",
    "        while success == False:\n",
    "            username_for_keyring = input(\"Enter your ArcGIS Online username:\") # If you are using VS Code, the text input dialog box appears at the top of the window\n",
    "            # Get the credential object\n",
    "            credential = keyring.get_credential(service_name, username_for_keyring)\n",
    "            # Check if the username is in the credential store\n",
    "            if credential is None:\n",
    "                print(f\"'{username_for_keyring}' is not in the local system's credential store. Try another username.\")\n",
    "            # Retrieve the password, login and set the GIS portal\n",
    "            else:\n",
    "                password_from_keyring = keyring.get_password(\"system\", username_for_keyring)\n",
    "                portal_url = 'https://www.arcgis.com'  \n",
    "                gis = GIS(portal_url, username=username_for_keyring, password=password_from_keyring)\n",
    "                success = True\n",
    "                # Print a success message with username and user's organization role\n",
    "                print(f\"Successfully logged in as: {gis.properties.user.username} (role: {gis.properties.user.role} userType: {gis.properties.user.userLicenseTypeId})\")\n",
    "    except ImportError:\n",
    "        print(\"The 'keyring' module is not installed. Please install it using 'pip install keyring'.\")\n",
    "        print(\"Before re-running this cell, open a command line window on your machine and run the command:\")\n",
    "        print(\"# python -m keyring set system <your_ago_username>\")\n",
    "        print(\"If using Windows Powershell, use:\")\n",
    "        print(\"# ./python -m keyring set system <your_ago_username>\")\n",
    "        print(\"You will be prompted to enter your password\")\n",
    "        print(\"When you hit Enter/Return the password will be saved to your local credential store.\")\n",
    "else:\n",
    "    gis = GIS(\"home\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Input the Classic StoryMap ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "719924d8992544edb4b57ebee3482114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Paste 32-digit Classic Esri Story Map id -->'), Text(value='d1799fc84e244c2f9af0e2â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 1: Input the classic StoryMap ID\n",
    "input_param2 = widgets.Text(value=\"d1799fc84e244c2f9af0e24ced4c95e1\", description=\"Item ID:\", layout=widgets.Layout(width='400px')) # test value: 597d573e58514bdbbeb53ba2179d2359\n",
    "user_line2 = widgets.HBox([widgets.Label(value=\"Paste 32-digit Classic Esri Story Map id -->\"), input_param2]) # TO DO add error checking logic and warning if item is missing or input is incorrect\n",
    "display(user_line2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fetch the Data\n",
    "This cell fetches the classic StoryMap item and parses its JSON data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched classic StoryMap: 'A World of Circles' (ID: d1799fc84e244c2f9af0e24ced4c95e1)\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Fetch the classic StoryMap's data\n",
    "classic_storymap_id = input_param2.value  # or set manually\n",
    "classic_item, classic_item_data = fetch_classic_storymap_data(classic_storymap_id, gis)\n",
    "if classic_item is None or classic_item_data is not None:\n",
    "    print(f\"Fetched classic StoryMap: '{classic_item.title}' (ID: {classic_item.itemid})\")\n",
    "else:\n",
    "    print(\"Could not fetch classic StoryMap data. Check the item ID and try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Parse Story Settings and Data\n",
    "\n",
    "This cell extracts the theme, title, subtitle, and entries from the classic StoryMap data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "panel position: left\n",
      "  series title: 'A World of Circles'\n",
      "   series type: bullet\n",
      "\n",
      "Found 15 entries in the Classic Map Series.\n",
      "1. Egmont National Park\n",
      "2. Manicoagan Reservoir\n",
      "3. Sun City\n",
      "4. Center-pivot irrigation\n",
      "5. Arc de Triomphe\n",
      "6. Eye of the Desert\n",
      "7. Victoria University\n",
      "8. Great Circle Earthworks, Newark, Ohio\n",
      "9. Arecibo Radio Observatory\n",
      "10. Mount St. Helens, Washington\n",
      "11. Kattenbroek, Netherlands\n",
      "12. Tevatron\n",
      "13. Stonehenge\n",
      "14. Las Ventas, Madrid, Spain\n",
      "15. Circles on the Earth\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Extract settings and entries\n",
    "classic_story_title, classic_story_subtitle, classic_story_type, classic_story_panel_position, classic_story_theme, entries = extract_story_settings(classic_item_data)\n",
    "if len(entries) == 1:\n",
    "    print(f\"{'panel position:':>15} {classic_story_panel_position}\")\n",
    "    print(f\"{'series title:':>15} '{classic_story_title}'\")\n",
    "    if classic_story_subtitle:\n",
    "        print(f\"{'subtitle:':>15} {classic_story_subtitle}\")\n",
    "    print(f\"{'series type:':>15} {classic_story_type}\")\n",
    "    print(f\"\\nFound {len(entries)} entry in the Classic Map Series.\")\n",
    "else:\n",
    "    print(f\"{'panel position:':>15} {classic_story_panel_position}\")\n",
    "    print(f\"{'series title:':>15} '{classic_story_title}'\")\n",
    "    if classic_story_subtitle:\n",
    "        print(f\"{'subtitle:':>15} {classic_story_subtitle}\")\n",
    "    print(f\"{'series type:':>15} {classic_story_type}\")\n",
    "    print(f\"\\nFound {len(entries)} entries in the Classic Map Series.\")    \n",
    "for i, e in enumerate(entries):\n",
    "    print(f\"{i+1}. {e['title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Determine StoryMap Theme\n",
    "\n",
    "This cell determines the new StoryMap theme based on the classic theme group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classic theme name: bullet-default-1-modified\n",
      "  New theme set to: SUMMIT\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Determine theme\n",
    "classic_name, new_theme = determine_theme(classic_story_theme)\n",
    "print(f\"Classic theme name: {classic_name}\")\n",
    "print(f\"{'New theme set to:':>19} {new_theme.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Loop Through and Process Each Entry's Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 of 15]: Egmont National Park                Media type: Map (id: 0bb11c0469f042b3afaf8b0d76572822)\n",
      "[2 of 15]: Manicoagan Reservoir                Media type: Map (id: 0bb11c0469f042b3afaf8b0d76572822)\n",
      "[3 of 15]: Sun City                            Media type: Map (id: 0bb11c0469f042b3afaf8b0d76572822)\n",
      "[4 of 15]: Center-pivot irrigation             Media type: Map (id: 0bb11c0469f042b3afaf8b0d76572822)\n",
      "Generated thumbnail is blank; scaling extent and retrying.\n",
      "[5 of 15]: Arc de Triomphe                     Media type: Map (id: 0bb11c0469f042b3afaf8b0d76572822)\n",
      "[6 of 15]: Eye of the Desert                   Media type: Map (id: 0bb11c0469f042b3afaf8b0d76572822)\n",
      "Generated thumbnail is blank; scaling extent and retrying.\n",
      "[7 of 15]: Victoria University                 Media type: Map (id: 0bb11c0469f042b3afaf8b0d76572822)\n",
      "Generated thumbnail is blank; scaling extent and retrying.\n",
      "[8 of 15]: Great Circle Earthworks, Newark, Ohio Media type: Map (id: 0bb11c0469f042b3afaf8b0d76572822)\n",
      "Generated thumbnail is blank; scaling extent and retrying.\n",
      "[9 of 15]: Arecibo Radio Observatory           Media type: Map (id: 0bb11c0469f042b3afaf8b0d76572822)\n",
      "[10 of 15]: Mount St. Helens, Washington        Media type: Map (id: 0bb11c0469f042b3afaf8b0d76572822)\n",
      "[11 of 15]: Kattenbroek, Netherlands            Media type: Map (id: 0bb11c0469f042b3afaf8b0d76572822)\n",
      "[12 of 15]: Tevatron                            Media type: Map (id: 0bb11c0469f042b3afaf8b0d76572822)\n",
      "[13 of 15]: Stonehenge                          Media type: Map (id: 0bb11c0469f042b3afaf8b0d76572822)\n",
      "[14 of 15]: Las Ventas, Madrid, Spain           Media type: Map (id: 0bb11c0469f042b3afaf8b0d76572822)\n",
      "[15 of 15]: Circles on the Earth                Media type: Map (id: 0bb11c0469f042b3afaf8b0d76572822)\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Loop through entries to process media, content and thumbnails\n",
    "entry_titles = [None] * len(entries)\n",
    "main_stage_contents = [None] * len(entries)\n",
    "thumbnail_paths = [None] * len(entries)\n",
    "invalid_webmaps = [False] * len(entries)\n",
    "final_webmap_jsons = [None] * len(entries)\n",
    "print_service_responses = [False] * len(entries)\n",
    "for i, entry in enumerate(entries):\n",
    "    entry_titles[i], main_stage_contents[i], thumbnail_paths[i], invalid_webmaps[i], final_webmap_jsons[i], print_service_responses[i] = process_entry(gis, entry, default_thumbnail_path, extents_dict=map_extents, entry_index=i)\n",
    "    if invalid_webmaps[i]:\n",
    "        print(f\"WARNING: There is a problem with the webmap in entry [{i+1} of {len(entries)}]: {entry_titles[i]}. Please fix before publishing the new StoryMap.\")\n",
    "    if type(main_stage_contents[i]).__name__ == \"Map\":\n",
    "        webmap_id = entries[i].get(\"media\", {}).get('webmap', {}).get('id')\n",
    "        print(f\"[{i+1} of {len(entries)}]: {entry_titles[i]:35} Media type: {type(main_stage_contents[i]).__name__} (id: {webmap_id})\")\n",
    "    elif type(main_stage_contents[i]).__name__ == \"Embed\":\n",
    "        embed_url = entries[i].get(\"media\", {}).get('webpage', {}).get('url')\n",
    "        print(f\"[{i+1} of {len(entries)}]: {entry_titles[i]:35} Media type: {type(main_stage_contents[i]).__name__} (link: {embed_url})\")\n",
    "    elif type(main_stage_contents[i]).__name__ == \"Image\":\n",
    "        image_name = entries[i].get(\"media\", {}).get('image', {}).get('title')\n",
    "        print(f\"[{i+1} of {len(entries)}]: {entry_titles[i]:35} Media type: {type(main_stage_contents[i]).__name__} (title: {image_name})\")\n",
    "    else:\n",
    "        print(f\"[{i+1} of {len(entries)}]: {entry_titles[i]:35} Media type: {type(main_stage_contents[i]).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Build an ArcGIS StoryMap with a Suppressed Cover Page for Each Entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 6: Loop through each tab and create a StoryMap for each\n",
    "published_storymap_items = []\n",
    "print(\"\\n***NOTICE*** You MUST click each link below to open the story in a new window. Check for errors, edit and continue publishing if necessary. ***NOTICE***\\n\\nIf you see an error message -- before troubleshooting further -â€” try just clicking the 'Publish' button. Doing so can fix many common issues.\\n\")\n",
    "for i, entry in enumerate(entries):\n",
    "    print(f\"[{i+1} of {len(entries)}]... \",end=\"\")\n",
    "    story, published_story_item = build_and_save_storymap(entry, i, entry[\"title\"], main_stage_contents[i], new_theme, thumbnail_paths[i], default_thumbnail_path)\n",
    "    if published_story_item:\n",
    "        published_storymap_items.append(published_story_item) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Build a Collection from the Published StoryMaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 7. Run the function to create the Collection\n",
    "collection_title, collection_url = build_collection(classic_item, published_storymap_items, thumbnail_paths, classic_story_type, new_theme)\n",
    "print(f\"Collection created: {collection_title} {collection_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"baseMap\": {\n",
      "    \"baseMapLayers\": [\n",
      "      {\n",
      "        \"id\": \"World_Imagery_2017\",\n",
      "        \"layerType\": \"ArcGISTiledMapServiceLayer\",\n",
      "        \"opacity\": 1,\n",
      "        \"visibility\": true,\n",
      "        \"url\": \"https://services.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer\"\n",
      "      }\n",
      "    ],\n",
      "    \"title\": \"Imagery\"\n",
      "  },\n",
      "  \"operationalLayers\": [],\n",
      "  \"spatialReference\": {\n",
      "    \"wkid\": 102100\n",
      "  },\n",
      "  \"mapOptions\": {\n",
      "    \"extent\": {\n",
      "      \"xmin\": -20037508.342789244,\n",
      "      \"ymin\": -4782120.616062363,\n",
      "      \"xmax\": -20037508.342789244,\n",
      "      \"ymax\": -4744437.161117821,\n",
      "      \"spatialReference\": {\n",
      "        \"wkid\": 102100\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"exportOptions\": {\n",
      "    \"outputSize\": [\n",
      "      800,\n",
      "      600\n",
      "    ],\n",
      "    \"dpi\": 96\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "data = final_webmap_jsons[0]\n",
    "for d in final_webmap_jsons[0]:\n",
    "    print(json.dumps(json.loads(d['params']['Web_Map_as_JSON']), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "      \"xmin\": -20721638.00383418,\n",
    "      \"ymin\": -4782120.616062363,\n",
    "      \"xmax\": -20674208.827783294,\n",
    "      \"ymax\": -4744437.161117821,\n",
    "test_json = {\n",
    "  \"baseMap\": {\n",
    "    \"baseMapLayers\": [\n",
    "      {\n",
    "        \"id\": \"World_Imagery_2017\",\n",
    "        \"layerType\": \"ArcGISTiledMapServiceLayer\",\n",
    "        \"opacity\": 1,\n",
    "        \"visibility\": True,\n",
    "        \"url\": \"https://services.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer\"\n",
    "      }\n",
    "    ],\n",
    "    \"title\": \"Imagery\"\n",
    "  },\n",
    "  \"operationalLayers\": [],\n",
    "  \"spatialReference\": {\n",
    "    \"wkid\": 102100\n",
    "  },\n",
    "  \"mapOptions\": {\n",
    "    \"extent\": {\n",
    "      \"xmin\": -20037508.342789244,\n",
    "      \"ymin\": -20037508.342789244,\n",
    "      \"xmax\": 20037508.342789244,\n",
    "      \"ymax\": 20037508.342789244,\n",
    "      \"spatialReference\": {\n",
    "        \"wkid\": 102100\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"exportOptions\": {\n",
    "    \"outputSize\": [\n",
    "      800,\n",
    "      600\n",
    "    ],\n",
    "    \"dpi\": 96\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_url = \"https://utility.arcgisonline.com/arcgis/rest/services/Utilities/PrintingTools/GPServer/Export%20Web%20Map%20Task/execute\"\n",
    "test_webmap = test_json\n",
    "test_params = {\n",
    "        \"f\": \"json\",\n",
    "        \"Web_Map_as_JSON\": json.dumps(test_webmap),\n",
    "        \"Format\": \"PNG32\",\n",
    "        \"Layout_Template\": \"MAP_ONLY\"\n",
    "        }\n",
    "\n",
    "response = requests.post(test_url, data=test_params)\n",
    "test_result = response.json()\n",
    "\n",
    "if 'results' in test_result:\n",
    "    image_url = test_result['results'][0]['value']['url']\n",
    "    img_response = requests.get(image_url)\n",
    "    if img_response.status_code == 200:\n",
    "        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.png')\n",
    "        temp_file.write(img_response.content)\n",
    "        temp_file.close()\n",
    "        img = PILImage.open(temp_file.name)\n",
    "        print(temp_file.name)\n",
    "        is_blank = is_blank_image(temp_file.name)\n",
    "        if is_blank:\n",
    "            print(\"Generated thumbnail is blank.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'webmap',\n",
       " 'webmap': {'id': '0bb11c0469f042b3afaf8b0d76572822',\n",
       "  'extent': {'xmin': -20037508.342789244,\n",
       "   'ymin': -4782120.616062363,\n",
       "   'xmax': -20037508.342789244,\n",
       "   'ymax': -4744437.161117821,\n",
       "   'spatialReference': {'wkid': 102100}},\n",
       "  'layers': [{'id': 'World_Dark_Gray_Base_Beta_4121', 'visibility': False},\n",
       "   {'id': 'mapNotes_2673_0', 'visibility': False}],\n",
       "  'popup': None,\n",
       "  'legend': {'enable': False, 'openByDefault': False}}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries[0]['media']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d0b9f962fe4fb5807d3b06d843be58",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "Map(extent={'xmin': -20721638.00383418, 'ymin': -4782120.616062363, 'xmax': -20674208.827783294, 'ymax': -4744â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "map2 = gis.map()\n",
    "map2.basemap.basemap = 'imagery'\n",
    "map2.extent = {\n",
    "      \"xmin\": -20721638.00383418,\n",
    "      \"ymin\": -4782120.616062363,\n",
    "      \"xmax\": -20674208.827783294,\n",
    "      \"ymax\": -4744437.161117821,\n",
    "    \"spatialReference\": {\"wkid\": 102100}\n",
    "}\n",
    "display(map2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad70a498dd22432a97a83bc417a418e7",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "Map(extent={'xmin': -20037508.342789244, 'ymin': -4782120.616062363, 'xmax': -20037508.342789244, 'ymax': -474â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map image saved to: https://utility.arcgisonline.com/arcgis/rest/directories/arcgisoutput/Utilities/PrintingTools_GPServer/x_____xr59HNaEjFL4YLQRWZFFavA..x_____x_ags_9754b29a-a621-11f0-9ace-0affc8ec20a7.png\n"
     ]
    }
   ],
   "source": [
    "test_media = entries[0]['media']\n",
    "\n",
    "# Create the map widget\n",
    "m = gis.map()\n",
    "\n",
    "# Set basemap if available\n",
    "if 'webmap' in test_media:\n",
    "    # Try to use the basemap from the webmap, fallback to 'topo'\n",
    "    basemap = 'topo'\n",
    "    try:\n",
    "        webmap_id = test_media['webmap'].get('id')\n",
    "        if webmap_id:\n",
    "            webmap_item = gis.content.get(webmap_id)\n",
    "            wm_data = webmap_item.get_data()\n",
    "            if 'baseMap' in wm_data and 'title' in wm_data['baseMap']:\n",
    "                basemap = wm_data['baseMap']['title'].lower()\n",
    "    except Exception:\n",
    "        pass\n",
    "    m.basemap.basemap = basemap\n",
    "\n",
    "    # Set extent if available\n",
    "    if 'extent' in test_media['webmap']:\n",
    "        m.extent = clamp_extent_to_spatial_reference(test_media['webmap']['extent'], test_media['webmap']['extent']['spatialReference'])\n",
    "\n",
    "# Display the map\n",
    "display(m)\n",
    "\n",
    "# Set the output file format\n",
    "file_format = \"PNG32\"\n",
    "\n",
    "print_extent = m.extent\n",
    "\n",
    "# Print the map to an image (returns a file path)\n",
    "image_path = m.print(file_format=file_format, extent=print_extent)\n",
    "print(\"Map image saved to:\", image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'spatialReference': {'wkid': 102100}, 'xmin': -20074580.301507503, 'ymin': -4786209.997075614, 'xmax': -20000436.384070985, 'ymax': -4740347.78010457}\n"
     ]
    }
   ],
   "source": [
    "print(m.extent)"
   ]
  }
 ],
 "metadata": {
  "esriNotebookRuntime": {
   "notebookRuntimeName": "ArcGIS Notebook Python 3 Standard",
   "notebookRuntimeVersion": "12.0"
  },
  "kernelspec": {
   "display_name": "arcgis-full",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
