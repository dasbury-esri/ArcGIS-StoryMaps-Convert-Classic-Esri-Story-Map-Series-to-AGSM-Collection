{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d832a5a",
   "metadata": {},
   "source": [
    "# Convert Classic Esri Tabbed StoryMap\n",
    "Fetch JSON from a Classic Esri Tabbed Story Map and convert each tab into its own ArcGIS StoryMap with the cover supressed. These StoryMaps can then be incoporated into an ArcGIS Collection to replcatee classic app look and feel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "952b01da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure imports and environment variables\n",
    "#import arcgis\n",
    "from bs4 import BeautifulSoup\n",
    "from arcgis.apps.storymap import StoryMap, Sidecar, Text, Image, Map, Embed, Themes\n",
    "from arcgis.gis import GIS, Item\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import json, re, requests, sys, time \n",
    "\n",
    "from arcgis.apps.storymap import StoryMap\n",
    "\n",
    "agoNotebook = False\n",
    "\n",
    "# Set Pandas dataframe display options\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns',1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df734021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:  3.11.11 (main, Mar  3 2025, 15:29:37) [MSC v.1938 64 bit (AMD64)]\n",
      "ArcGIS for Python API version:  2.4.1\n"
     ]
    }
   ],
   "source": [
    "# Print Python and ArcGIS for Python versions\n",
    "import sys\n",
    "print(f\"Python version: \",sys.version)\n",
    "import arcgis\n",
    "print(\"ArcGIS for Python API version: \",arcgis.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "247637cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully logged in as: dasbury_storymaps (role: org_admin)\n"
     ]
    }
   ],
   "source": [
    "# Connect to ArcGIS Online\n",
    "# Define the GIS\n",
    "if agoNotebook == False:\n",
    "    import keyring\n",
    "    service_name = \"system\" # Use the default local credential store\n",
    "    success = False # Set initial state\n",
    "\n",
    "    # Ask for the username\n",
    "    while success == False:\n",
    "        username_for_keyring = input(\"Enter your ArcGIS Online username:\") # If you are using VS Code, the text input dialog box appears at the top of the window\n",
    "        # Get the credential object\n",
    "        credential = keyring.get_credential(service_name, username_for_keyring)\n",
    "        # Check if the username is in the credential store\n",
    "        if credential is None:\n",
    "            print(f\"'{username_for_keyring}' is not in the local system's credential store. Try another username.\")\n",
    "        # Retrieve the password, login and set the GIS portal\n",
    "        else:\n",
    "            password_from_keyring = keyring.get_password(\"system\", username_for_keyring)\n",
    "            portal_url = 'https://www.arcgis.com'  \n",
    "            gis = GIS(portal_url, username=username_for_keyring, password=password_from_keyring)\n",
    "            success = True\n",
    "            # Print a success message with username and user's organization role\n",
    "            print(\"Successfully logged in as: \" + gis.properties.user.username, \"(role: \" + gis.properties.user.role + \")\")\n",
    "else:\n",
    "    gis = GIS(\"home\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fe314657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Classic StoryMap item id\n",
    "classic_storymap_id = '597d573e58514bdbbeb53ba2179d2359'\n",
    "# Fetch the StoryMap Item from AGO\n",
    "classic_item = Item(gis=gis,itemid=classic_storymap_id)\n",
    "# Fetch the StoryMap data\n",
    "classic_data = Item.get_data(classic_item)\n",
    "if type(classic_data) == dict:\n",
    "    classic_item_json = json.dumps(classic_data)\n",
    "    classic_item_data = json.loads(classic_item_json)\n",
    "else:\n",
    "    classic_item_data = json.loads(classic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cbf3ad07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to extract HTML side panel text\n",
    "def parse_html_to_story_content(description_html):\n",
    "    soup = BeautifulSoup(description_html, \"html.parser\")\n",
    "    content_nodes = []\n",
    "    \n",
    "    # Parse each image-container div separately, handling nested containers as separate units\n",
    "    image_containers = soup.find_all(\"div\", class_=\"image-container\")\n",
    "    print(f\"Found {len(image_containers)} image containers\")\n",
    "    processed_containers = set()\n",
    "    \n",
    "    for container in image_containers:\n",
    "        if container in processed_containers:\n",
    "            continue\n",
    "        \n",
    "        # Mark all nested containers inside this one as processed to avoid duplication\n",
    "        nested_containers = container.find_all(\"div\", class_=\"image-container\")\n",
    "        processed_containers.update(nested_containers)\n",
    "        processed_containers.add(container)\n",
    "        \n",
    "        # Extract images inside this container\n",
    "        imgs = container.find_all(\"img\")\n",
    "        print(f\"Found {len(imgs)} images within image container\")\n",
    "        for img in imgs:\n",
    "            src = img.get(\"src\")\n",
    "            alt = img.get(\"alt\", \"\")\n",
    "            if src:\n",
    "                img_obj = Image(src)\n",
    "                img_obj.alt_text = alt\n",
    "                content_nodes.append(img_obj)\n",
    "        \n",
    "        # Extract styled text inside container preserving inline HTML (for rich text)\n",
    "        # Extract text from the container, joining nested elements with a space\n",
    "        text_content = container.get_text(separator=' ', strip=True)\n",
    "        # Use inner HTML excluding images (already processed)\n",
    "        styles = []\n",
    "        spans = soup.find_all(\"span\", style=True)\n",
    "        if spans:\n",
    "            for span in spans:\n",
    "                style = span.get(\"style\")\n",
    "                styles.append(style)\n",
    "            print(styles)\n",
    "        # Remove images tags to avoid duplication in text\n",
    "        for img in imgs:\n",
    "            img.decompose()\n",
    "        print(text_content)\n",
    "        \n",
    "        # Get remaining inner HTML as string\n",
    "        inner_html = ''.join(str(e) for e in container.contents).strip()\n",
    "        if inner_html:\n",
    "            # Use the raw HTML inside a Text node to keep inline styling\n",
    "            text_node = Text()\n",
    "            text_node.text = inner_html\n",
    "            content_nodes.append(text_node)\n",
    "    \n",
    "    # For content outside of image-container divs, parse remaining paragraphs, links, etc.\n",
    "    # Remove all image-container divs to avoid duplicates\n",
    "    for img_cont in image_containers:\n",
    "        img_cont.decompose()\n",
    "    \n",
    "    # Parse remaining paragraphs\n",
    "    para = soup.find_all(\"p\")\n",
    "    print(f\"Found {len(para)} paragraphs outside image containers\")\n",
    "    for p in soup.find_all(\"p\"):\n",
    "        html_content = str(p)\n",
    "        print(html_content)\n",
    "        if html_content:\n",
    "            text_node = Text()\n",
    "            text_node.text = html_content\n",
    "            content_nodes.append(text_node)\n",
    "            #print(text_node.text)\n",
    "    \n",
    "    # Parse standalone links for embedding\n",
    "    for a in soup.find_all(\"a\"):\n",
    "        href = a.get(\"href\")\n",
    "        if href:\n",
    "            content_nodes.append(Embed(href))\n",
    "    \n",
    "    print(f\"Found {len(content_nodes)} elements\")\n",
    "    return content_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5d83a9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 image containers\n",
      "Found 1 images within image container\n",
      "['color:#E5FA84', 'font-size:20px', 'font-size:12px', 'color:#E2F782', 'font-size:10px']\n",
      "Hurricane Katrina displaced over one million Louisiana residents -- an estimated 277,000 did not come back to resettle.\n",
      "Found 0 images within image container\n",
      "['color:#E5FA84', 'font-size:20px', 'font-size:12px', 'color:#E2F782', 'font-size:10px']\n",
      "\n",
      "Found 6 paragraphs outside image containers\n",
      "<p style=\"text-align:center\"><img alt=\"\" height=\"132\" src=\"https://lh3.googleusercontent.com/-Frhyo5iY8mo/Vc40Ea084sI/AAAAAAAAAEY/r_AIGqcYI9E/s1600/legends-03.png\" width=\"402\"/></p>\n",
      "<p> </p>\n",
      "<p><span style=\"font-size:12px\">Threatened by one of the most destructive and influential storms in United States history, those living in the path of Hurricane Katrina fled to every state in the country, with many unable to return home to Louisiana after the storm left. This map, which uses data from the 2006 American Community Survey, presents a good, but imperfect illustration of where evacuees ended up by showing where residents who lived in Louisiana in 2005 moved to as of 2006. <span style=\"color:#E2F782\"><strong>Click on each state</strong></span> for details. </span></p>\n",
      "<p> </p>\n",
      "<p><span style=\"font-size:10px\">Data Sources: <a href=\"https://www.census.gov/hhes/migration/data/acs/state-to-state.html\" target=\"_blank\">2006 American Community Survey 1-year Estimates, State-to-State Migration Flows</a>, <a href=\"http://www.nhc.noaa.gov/\" target=\"_blank\">NHC</a>, <a href=\"http://www.noaa.gov/\" target=\"_blank\">NOAA</a>, <a href=\"https://www.weather.gov/\" target=\"_blank\">NWS</a>. </span></p>\n",
      "<p> </p>\n",
      "Found 13 elements\n",
      "Created replica of The Katrina Diaspora\n",
      "Created 1 StoryMaps\n"
     ]
    }
   ],
   "source": [
    "# Extract entries list\n",
    "entries = classic_item_data[\"values\"][\"story\"][\"entries\"]\n",
    "\n",
    "# Fetch theme group\n",
    "theme_group = classic_item_data[\"values\"][\"settings\"][\"theme\"][\"colors\"][\"group\"]\n",
    "if theme_group == \"dark\":\n",
    "    new_theme = Themes.OBSIDIAN\n",
    "elif theme_group == \"light\":\n",
    "    new_theme = Themes.SUMMIT\n",
    "\n",
    "created_storymaps = []\n",
    "loop_limit = 1\n",
    "for i, entry in enumerate(entries):\n",
    "    # Create a new StoryMap\n",
    "    story = StoryMap()\n",
    "    story.theme(new_theme)\n",
    "\n",
    "    # Create Sidecar immersive section\n",
    "    sidecar = Sidecar(style=\"docked-panel\")\n",
    "\n",
    "    # Add Sidecar to story\n",
    "    story.add(sidecar)\n",
    "\n",
    "    # Determine media content for main stage\n",
    "    media_info = entry.get(\"media\", {})\n",
    "    media_type = media_info.get(\"type\")\n",
    "\n",
    "    media_content = None\n",
    "    if media_type == \"webmap\":\n",
    "        webmap_id = media_info.get('webmap', {}).get('id')\n",
    "        if webmap_id:\n",
    "            media_content = Map(webmap_id)\n",
    "    elif media_type == \"webpage\":\n",
    "        webpage_url = media_info.get(\"webpage\", {}).get(\"url\")\n",
    "        if webpage_url:\n",
    "            media_content = Embed(webpage_url)\n",
    "\n",
    "    # Create text panel content from description (HTML)\n",
    "    description_html = entry.get(\"description\", \"\")\n",
    "    text_panel = Text(description_html)\n",
    "\n",
    "    # Convert HTML from side panel to AGSM content items\n",
    "    narrative_nodes = parse_html_to_story_content(description_html)\n",
    "\n",
    "    # Add a slide to the sidecar with text panel and main media\n",
    "    sidecar.add_slide(contents=narrative_nodes, media=media_content)\n",
    "\n",
    "    # Set webmap properties. Map must be added to the story before setting viewpoint\n",
    "    if media_type == \"webmap\":\n",
    "        # Set the extent for the map stage\n",
    "        extent_json = media_info.get('webmap', {}).get('extent')\n",
    "        if extent_json:\n",
    "            media_content.set_viewpoint(extent=extent_json)  # Extent dict per docs\n",
    "        # Set layer visibility (if StoryMap Map object supports)\n",
    "        layers = media_info.get('webmap', {}).get('layers', [])\n",
    "        if hasattr(media_content, \"layers\"):\n",
    "            for lyr in media_content.layers:\n",
    "                for lyr_json in layers:\n",
    "                    if lyr.id == lyr_json['id']:\n",
    "                        lyr.visible = lyr_json['visibility']\n",
    "\n",
    "    # Hide the cover by setting 'hide_cover' - this is conceptual; actual implementation may vary\n",
    "    # You may need to modify the story's cover node or settings to hide it as per API capabilities\n",
    "    story.hide_cover = True  # If available; alternatively configure via story resources/settings\n",
    "\n",
    "    # Save and publish storymap\n",
    "    story_title = entry.get(\"title\", \"Untitled Story\")\n",
    "    #story.save(title=story_title, tags=[\"auto-created\"], publish=True)\n",
    "\n",
    "    created_storymaps.append(story)\n",
    "    print(f\"Created replica of {story_title}\")\n",
    "    if i < loop_limit:\n",
    "        break\n",
    "\n",
    "print(f\"Created {len(created_storymaps)} StoryMaps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3560a533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"image-container\">\n",
      "<div class=\"image-container\">\n",
      "<p style=\"text-align:center\"><img alt=\"\" src=\"https://lh3.googleusercontent.com/-OZs54tCn6mM/VdYjIf-XQ0I/AAAAAAAAAOU/HrFElBu60xw/s1600/legends-08.png\" width=\"496\" height=\"240\"></p>\n",
      "</div>\n",
      "&nbsp;\n",
      "\n",
      "<div class=\"image-container\">&nbsp;</div>\n",
      "\n",
      "<div class=\"image-container\"><span style=\"color:#E5FA84\"><span style=\"font-size:20px\"><strong>Hurricane Katrina displaced over one million Louisiana residents -- an estimated 277,000 did not come back to resettle.</strong>&nbsp;</span></span></div>\n",
      "</div>\n",
      "\n",
      "<p style=\"text-align:center\"><img alt=\"\" src=\"https://lh3.googleusercontent.com/-Frhyo5iY8mo/Vc40Ea084sI/AAAAAAAAAEY/r_AIGqcYI9E/s1600/legends-03.png\" width=\"402\" height=\"132\"></p>\n",
      "\n",
      "<p>&nbsp;</p>\n",
      "\n",
      "<div>\n",
      "<p><span style=\"font-size:12px\">Threatened by one of the most destructive and influential storms in United States history, those living in the path of Hurricane Katrina&nbsp;fled to every state in the country, with many&nbsp;unable to return home to Louisiana after the storm left.&nbsp;This map, which uses data from the 2006 American Community Survey,&nbsp;presents a good, but imperfect illustration of&nbsp;where evacuees ended up by showing&nbsp;where&nbsp;residents who lived in Louisiana&nbsp;in 2005 moved to as of 2006.&nbsp;<span style=\"color:#E2F782\"><strong>Click on each state</strong></span>&nbsp;for details.&nbsp;</span></p>\n",
      "\n",
      "<p>&nbsp;</p>\n",
      "\n",
      "<p><span style=\"font-size:10px\">Data Sources:&nbsp;<a href=\"https://www.census.gov/hhes/migration/data/acs/state-to-state.html\" target=\"_blank\">2006 American Community Survey 1-year Estimates, State-to-State Migration Flows</a>,&nbsp;<a href=\"http://www.nhc.noaa.gov/\" target=\"_blank\">NHC</a>,&nbsp;<a href=\"http://www.noaa.gov/\" target=\"_blank\">NOAA</a>, <a href=\"https://www.weather.gov/\" target=\"_blank\">NWS</a>.&nbsp;</span></p>\n",
      "\n",
      "<p>&nbsp;</p>\n",
      "</div>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(description_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a9cdd69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Image, Image, Text: paragraph, Text: paragraph, Embed: https://www.census.gov/hhes/migration/data/acs/state-to-state.html, Embed: http://www.nhc.noaa.gov/, Embed: http://www.noaa.gov/, Embed: https://www.weather.gov/, Text: paragraph, Text: paragraph, Text: paragraph]\n"
     ]
    }
   ],
   "source": [
    "print(narrative_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111e8aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract HTML from side panel and create story content elements from it\n",
    "def parse_html_to_story_content(description_html):\n",
    "    soup = BeautifulSoup(description_html, \"html.parser\")\n",
    "    content_nodes = []\n",
    "    # Parse images\n",
    "    for img in soup.find_all(\"img\"):\n",
    "        src = img.get(\"src\")\n",
    "        alt = img.get(\"alt\", \"\")\n",
    "        if src:\n",
    "            img_obj = Image(src)\n",
    "            img_obj.alt_text = alt\n",
    "            content_nodes.append(img_obj)\n",
    "    # Parse paragraphs & div text\n",
    "    for p in soup.find_all(\"p\"):\n",
    "        txt = p.get_text(strip=True)\n",
    "        if txt:\n",
    "            content_nodes.append(Text(txt))\n",
    "    # Parse links for embedding\n",
    "    for a in soup.find_all(\"a\"):\n",
    "        href = a.get(\"href\")\n",
    "        if href:\n",
    "            content_nodes.append(Embed(href))\n",
    "    # Fallback for extra descriptive divs/spans etc.\n",
    "    for div in soup.find_all(\"div\"):\n",
    "        txt = div.get_text(strip=True)\n",
    "        if txt and not any(txt == n for n in content_nodes):\n",
    "            content_nodes.append(Text(txt))\n",
    "    return content_nodes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arcgispro-py3-vscode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
