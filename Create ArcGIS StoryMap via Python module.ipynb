{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d832a5a",
   "metadata": {},
   "source": [
    "# Convert Classic Esri Tabbed StoryMap\n",
    "Fetch JSON from a Classic Esri Tabbed Story Map and convert each tab into its own ArcGIS StoryMap with the cover supressed. These StoryMaps can then be incoporated into an ArcGIS Collection to replcatee classic app look and feel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952b01da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure imports and environment variables\n",
    "import arcgis\n",
    "from bs4 import BeautifulSoup\n",
    "from arcgis.apps.storymap import StoryMap, Sidecar, Text, TextStyles, Image, Map, Embed, Themes, Cover\n",
    "from arcgis.gis import GIS, Item\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import json, re, requests, sys, time \n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Set Pandas dataframe display options\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns',1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf3ad07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to extract HTML side panel content\n",
    "# all possible options:  Image | Video | Audio | Embed | Map | Button | Text | Gallery | Timeline | Sidecar | Code | Table \n",
    "\n",
    "def deduplicate_by_containment(elements):\n",
    "    # Create list of (element, outer_html_str) tuples\n",
    "    elems_and_html = [(el, ' '.join(str(el).split())) for el in elements]\n",
    "\n",
    "    keep = []\n",
    "    for i, (el_i, html_i) in enumerate(elems_and_html):\n",
    "        # Check if this element is contained within another (excluding itself)\n",
    "        contained = False\n",
    "        for j, (el_j, html_j) in enumerate(elems_and_html):\n",
    "            if i != j and html_i in html_j:\n",
    "                contained = True\n",
    "                break\n",
    "        if not contained:\n",
    "            keep.append(el_i)\n",
    "    return keep\n",
    "\n",
    "def convert_color_style_to_class(tag):\n",
    "    # Check if tag has 'style' attribute with color\n",
    "    style = tag.get('style', '')\n",
    "    # Regex to find color property (hex, rgb, named colors)\n",
    "    match = re.search(r'color\\s*:\\s*([^;]+)', style, re.IGNORECASE)\n",
    "    if match:\n",
    "        color_value = match.group(1).strip()\n",
    "        # Convert hex (#XXXXXX) to class name, removing #\n",
    "        if color_value.startswith('#'):\n",
    "            class_color = f\"sm-text-color-{color_value[1:].upper()}\"\n",
    "        else:\n",
    "            # For rgb or named color, sanitize usable string (replace spaces/paren)\n",
    "            sanitized = re.sub(r'[\\s\\(\\)]', '', color_value).replace(',', '-')\n",
    "            class_color = f\"sm-text-color-{sanitized.upper()}\"\n",
    "        # Remove color from style attribute\n",
    "        new_style = re.sub(r'color\\s*:\\s*[^;]+;?', '', style, flags=re.IGNORECASE).strip()\n",
    "        if new_style:\n",
    "            tag['style'] = new_style\n",
    "        else:\n",
    "            del tag['style']\n",
    "        # Add or append class attribute\n",
    "        if 'class' in tag.attrs:\n",
    "            tag['class'].append(class_color)\n",
    "        else:\n",
    "            tag['class'] = [class_color]\n",
    "\n",
    "def process_html_colors_preserve_html(html_text):\n",
    "    soup = BeautifulSoup(html_text, \"html.parser\")\n",
    "    # Iterate over tags that can have styles: div, span, strong, em, p, etc.\n",
    "    for tag in soup.find_all(True):\n",
    "        convert_color_style_to_class(tag)\n",
    "    return str(soup)\n",
    "\n",
    "def parse_p_to_text_elements(div_html):\n",
    "    soup = BeautifulSoup(div_html, \"html.parser\")\n",
    "    text_elements = []\n",
    "    # Find direct <p> children\n",
    "    for p in soup.find_all(\"p\"): #, recursive=False):\n",
    "        # Get inner HTML (including styled spans, links, etc.)\n",
    "        inner_html = ''.join(str(c) for c in p.contents)\n",
    "        converted_html = process_html_colors_preserve_html(inner_html)\n",
    "        # Convert inline CSS color to AGSM compatible color\n",
    "        # <span style=\"color:#E2F782\"> becomes <span class=\"sm-text-color-E2F782\">\n",
    "        # Create a Text node with \"paragraph\" style\n",
    "        # https://developers.arcgis.com/python/latest/api-reference/arcgis.apps.storymap.html#arcgis.apps.storymap.story_content.Text\n",
    "        text_node = Text(text=converted_html, style=TextStyles.PARAGRAPH)\n",
    "        text_elements.append(text_node)\n",
    "    return text_elements\n",
    "\n",
    "def parse_p_to_image_elements(div_html):\n",
    "    soup = BeautifulSoup(div_html, \"html.parser\")\n",
    "    img_elements = []\n",
    "    # Find direct <p> children\n",
    "    for p in soup.find_all(\"p\"):\n",
    "        img = p.find(\"img\")  # Find <img> inside <p>\n",
    "        # Get inner HTML (including styled spans, links, etc.)\n",
    "        inner_html = ''.join(str(c) for c in p.contents)\n",
    "\n",
    "        if img:\n",
    "            src_url = img.get(\"src\", \"\")  # Extract src attribute safely\n",
    "            alt_text = img.get(\"alt\", \"\") # Extract alt text\n",
    "            # Create a Image node and set properties\n",
    "            # https://developers.arcgis.com/python/latest/api-reference/arcgis.apps.storymap.html#arcgis.apps.storymap.story_content.Image\n",
    "            img_node = Image(path=src_url)\n",
    "            img_node.alt_text = alt_text\n",
    "            img_node.caption = \"\"\n",
    "            img_node.link = \"\"\n",
    "            img_node.image = src_url  # Assign image property. TO DO fix this for images hosted on AGO\n",
    "            \n",
    "            img_elements.append(img_node)\n",
    "    return img_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5f48e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6736cd01b21d4f7fb9c385ef772c49b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Paste 32-digit Classic Esri Story Map id -->'), Text(value='597d573â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create widgets\n",
    "# Create checkbox as a variable\n",
    "input_param1 = widgets.Checkbox(value=False, description=\"Yes\")\n",
    "user_line1 = widgets.HBox([widgets.Label(value=\"Are you running this within ArcGIS Online?\"),input_param1])\n",
    "input_param2 = widgets.Text(value=\"597d573e58514bdbbeb53ba2179d2359\", description=\"Story ID:\")\n",
    "user_line2 = widgets.HBox([widgets.Label(value=\"Paste 32-digit Classic Esri Story Map id -->\"), input_param2]) # TO DO add error checking logic and warning\n",
    "submit_btn = widgets.Button(description=\"Convert Story\")\n",
    "output_box = widgets.Output()\n",
    "def on_submit(btn):\n",
    "    output_box.clear_output()\n",
    "    try:\n",
    "        agoNotebook = input_param1.value\n",
    "        classic_storymap_id = input_param2.value  \n",
    "\n",
    "        # Print Python and ArcGIS for Python versions since things can change between versions\n",
    "        print(f\"Python version: \",sys.version)\n",
    "        print(\"ArcGIS for Python API / StoryMap module version: \",arcgis.__version__) \n",
    "\n",
    "        # Connect to ArcGIS Online\n",
    "        # Define the GIS\n",
    "        if agoNotebook == False:\n",
    "            import keyring\n",
    "            service_name = \"system\" # Use the default local credential store\n",
    "            success = False # Set initial state\n",
    "\n",
    "            # Ask for the username\n",
    "            while success == False:\n",
    "                username_for_keyring = input(\"Enter your ArcGIS Online username:\") # If you are using VS Code, the text input dialog box appears at the top of the window\n",
    "                # Get the credential object\n",
    "                credential = keyring.get_credential(service_name, username_for_keyring)\n",
    "                # Check if the username is in the credential store\n",
    "                if credential is None:\n",
    "                    print(f\"'{username_for_keyring}' is not in the local system's credential store. Try another username.\")\n",
    "                # Retrieve the password, login and set the GIS portal\n",
    "                else:\n",
    "                    password_from_keyring = keyring.get_password(\"system\", username_for_keyring)\n",
    "                    portal_url = 'https://www.arcgis.com'  \n",
    "                    gis = GIS(portal_url, username=username_for_keyring, password=password_from_keyring)\n",
    "                    success = True\n",
    "                    # Print a success message with username and user's organization role\n",
    "                    print(\"Successfully logged in as: \" + gis.properties.user.username, \"(role: \" + gis.properties.user.role + \")\")\n",
    "        else:\n",
    "            gis = GIS(\"home\")\n",
    "\n",
    "        # Define the Classic StoryMap item id\n",
    "        #classic_storymap_id = '597d573e58514bdbbeb53ba2179d2359'\n",
    "        # Fetch the StoryMap Item from AGO\n",
    "        classic_item = Item(gis=gis,itemid=classic_storymap_id)\n",
    "        # Fetch the StoryMap data\n",
    "        classic_data = Item.get_data(classic_item)\n",
    "        if type(classic_data) == dict:\n",
    "            classic_item_json = json.dumps(classic_data)\n",
    "            classic_item_data = json.loads(classic_item_json)\n",
    "        else:\n",
    "            classic_item_data = json.loads(classic_data)\n",
    "\n",
    "        # Extract story data\n",
    "        classic_story_settings = classic_item_data[\"values\"][\"settings\"]\n",
    "        classic_story_theme = classic_story_settings[\"theme\"]\n",
    "        classic_story_title = classic_item_data[\"values\"][\"title\"]\n",
    "        classic_story_data = classic_item_data[\"values\"][\"story\"]\n",
    "\n",
    "        # Extract tabs (entries list)\n",
    "        entries = classic_story_data[\"entries\"]\n",
    "\n",
    "        # Fetch theme group\n",
    "        classic_theme_group = classic_story_theme[\"colors\"][\"group\"]\n",
    "        if classic_theme_group == \"dark\":\n",
    "            new_theme = Themes.OBSIDIAN\n",
    "        elif classic_theme_group == \"light\":\n",
    "            new_theme = Themes.SUMMIT\n",
    "\n",
    "        created_storymaps = []\n",
    "        loop_limit = 3 # for testing/debugging only\n",
    "        for i, entry in enumerate(entries):\n",
    "            # Create a new StoryMap\n",
    "            story = StoryMap()\n",
    "            story.theme(new_theme)\n",
    "\n",
    "            # Create Sidecar immersive section\n",
    "            sidecar = Sidecar(style=\"docked-panel\")\n",
    "\n",
    "            # Add Sidecar to story\n",
    "            story.add(sidecar)\n",
    "\n",
    "            # Determine media content for main stage\n",
    "            media_info = entry.get(\"media\", {})\n",
    "            media_type = media_info.get(\"type\")\n",
    "\n",
    "            media_content = None\n",
    "            if media_type == \"webmap\":\n",
    "                webmap_id = media_info.get('webmap', {}).get('id')\n",
    "                if webmap_id:\n",
    "                    media_content = Map(webmap_id)\n",
    "            elif media_type == \"webpage\":\n",
    "                webpage_url = media_info.get(\"webpage\", {}).get(\"url\")\n",
    "                if webpage_url:\n",
    "                    media_content = Embed(webpage_url)\n",
    "\n",
    "            # Fetch content from description (HTML)\n",
    "            description_html = entry.get(\"description\", \"\")\n",
    "\n",
    "            # Convert HTML from side panel to AGSM content items\n",
    "            soup = BeautifulSoup(description_html, \"html.parser\")\n",
    "            all = soup.find_all()\n",
    "            all_list = list(all)\n",
    "            unique_top_level = deduplicate_by_containment(all_list)\n",
    "            first_element = deduplicate_by_containment(unique_top_level[0])\n",
    "\n",
    "            img_snippet1 = str(unique_top_level[0])\n",
    "            img_nodes1 = parse_p_to_image_elements(img_snippet1)\n",
    "\n",
    "            html_snippet1 = str(first_element[2])\n",
    "            converted_html2 = process_html_colors_preserve_html(html_snippet1)\n",
    "            text_nodes1 = [Text(text=converted_html2, style=TextStyles.PARAGRAPH)]\n",
    "\n",
    "            img_snippet = str(unique_top_level[1])\n",
    "            img_nodes = parse_p_to_image_elements(img_snippet)\n",
    "\n",
    "            html_snippet = str(unique_top_level[2])\n",
    "            text_nodes = parse_p_to_text_elements(html_snippet)\n",
    "\n",
    "            narrative_nodes = img_nodes1 + text_nodes1 + img_nodes + text_nodes\n",
    "                \n",
    "            #narrative_nodes = parse_html_to_story_content(description_html)\n",
    "\n",
    "            # Create text panel from narrative nodes\n",
    "            text_panel = Text(narrative_nodes)\n",
    "            #story.add(text_panel)\n",
    "\n",
    "            # Add a slide to the sidecar with text panel and main media\n",
    "            sidecar.add_slide(contents=narrative_nodes, media=media_content)  \n",
    "\n",
    "            # Set webmap properties. Map must be added to the story before setting viewpoint\n",
    "            if media_type == \"webmap\":\n",
    "                # Set the extent for the map stage\n",
    "                extent_json = media_info.get('webmap', {}).get('extent')\n",
    "                if extent_json:\n",
    "                    media_content.set_viewpoint(extent=extent_json)  # Extent dict per docs\n",
    "                # Set layer visibility (if StoryMap Map object supports)\n",
    "                old_layers = media_info.get('webmap', {}).get('layers', [])\n",
    "                if hasattr(media_content, \"map_layers\"):\n",
    "                    for new_lyr in media_content.map_layers:\n",
    "                        for old_lyr in old_layers:\n",
    "                            if new_lyr['id'] == old_lyr['id']:\n",
    "                                new_lyr['visible'] = old_lyr['visibility']\n",
    "            \n",
    "            # Set Cover properties\n",
    "            cover_properties = story.content_list[0]\n",
    "            cover_properties.byline = \"\"\n",
    "            cover_properties.date = \"none\"\n",
    "            #cover_properties.media = createThumbnail() # figure out a way to create a thumbnail from the first Sidecar media item\n",
    "\n",
    "            # As the Cover class does not include a setting to hide the cover, we hide it by adding the 'config' key\n",
    "            # to the Cover json\n",
    "            for k,v in story.properties['nodes'].items():\n",
    "                if v['type'] == 'storycover':\n",
    "                    v['config'] = {'isHidden': 'true'}\n",
    "\n",
    "\n",
    "            # Save and publish storymap\n",
    "            story_title = entry.get(\"title\", \"Untitled Story\")\n",
    "            story.save(title=story_title, tags=[\"auto-created\"], publish=True)\n",
    "\n",
    "            # TO DO add an AGO relationship so if an attempt is made to delete story from My Content a warning is issued that the story\n",
    "            # is included in a Collection (and give the name/id of the Collection(s) where it is referenced)\n",
    "\n",
    "            created_storymaps.append(story)\n",
    "            print(f\"Created replica of {story_title}\")\n",
    "            if i > loop_limit:\n",
    "                break\n",
    "\n",
    "        print(f\"Created {len(created_storymaps)} StoryMaps\")\n",
    "        with output_box:\n",
    "            print(\"Success! Classic Story Map converted to AGSM Collection\")\n",
    "    except Exception as e:\n",
    "        with output_box:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "submit_btn.on_click(on_submit)\n",
    "\n",
    "# Display UI elements\n",
    "display(widgets.VBox([user_line2, user_line1, submit_btn, output_box]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ed076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def parse_html_to_story_content(description_html):\n",
    "#     soup = BeautifulSoup(description_html, \"html.parser\")\n",
    "#     content_nodes = []\n",
    "    \n",
    "#     # Parse each image-container div separately, handling nested containers as separate units\n",
    "#     image_containers = soup.find_all(\"div\", class_=\"image-container\")\n",
    "#     print(f\"Found {len(image_containers)} image containers\")\n",
    "#     processed_containers = set()\n",
    "    \n",
    "#     for container in image_containers:\n",
    "#         if container in processed_containers:\n",
    "#             continue\n",
    "        \n",
    "#         # Mark all nested containers inside this one as processed to avoid duplication\n",
    "#         nested_containers = container.find_all(\"div\", class_=\"image-container\")\n",
    "#         processed_containers.update(nested_containers)\n",
    "#         processed_containers.add(container)\n",
    "        \n",
    "#         # Extract images inside this container\n",
    "#         imgs = container.find_all(\"img\")\n",
    "#         print(f\"Found {len(imgs)} images within image container\")\n",
    "#         for img in imgs:\n",
    "#             src = img.get(\"src\")\n",
    "#             alt = img.get(\"alt\", \"\")\n",
    "#             if src:\n",
    "#                 img_obj = Image(src)\n",
    "#                 img_obj.alt_text = alt\n",
    "#                 content_nodes.append(img_obj)\n",
    "        \n",
    "#         # Extract styled text inside container preserving inline HTML (for rich text)\n",
    "#         # Extract text from the container, joining nested elements with a space\n",
    "#         text_content = container.get_text(separator=' ', strip=True)\n",
    "#         # Use inner HTML excluding images (already processed)\n",
    "#         styles = []\n",
    "#         spans = soup.find_all(\"span\", style=True)\n",
    "#         if spans:\n",
    "#             for span in spans:\n",
    "#                 style = span.get(\"style\")\n",
    "#                 styles.append(style)\n",
    "#             print(styles)\n",
    "#         # Remove images tags to avoid duplication in text\n",
    "#         for img in imgs:\n",
    "#             img.decompose()\n",
    "#         print(text_content)\n",
    "        \n",
    "#         # Get remaining inner HTML as string\n",
    "#         inner_html = ''.join(str(e) for e in container.contents).strip()\n",
    "#         if inner_html:\n",
    "#             # Use the raw HTML inside a Text node to keep inline styling\n",
    "#             text_node = Text()\n",
    "#             text_node.text = inner_html\n",
    "#             content_nodes.append(text_node)\n",
    "    \n",
    "#     # For content outside of image-container divs, parse remaining paragraphs, links, etc.\n",
    "#     # Remove all image-container divs to avoid duplicates\n",
    "#     for img_cont in image_containers:\n",
    "#         img_cont.decompose()\n",
    "    \n",
    "#     # Parse remaining paragraphs\n",
    "#     para = soup.find_all(\"p\")\n",
    "#     print(f\"Found {len(para)} paragraphs outside image containers\")\n",
    "#     for p in soup.find_all(\"p\"):\n",
    "#         html_content = str(p)\n",
    "#         print(html_content)\n",
    "#         if html_content:\n",
    "#             text_node = Text()\n",
    "#             text_node.text = html_content\n",
    "#             content_nodes.append(text_node)\n",
    "#             #print(text_node.text)\n",
    "    \n",
    "#     # Parse standalone links for embedding\n",
    "#     # for a in soup.find_all(\"a\"):\n",
    "#     #     href = a.get(\"href\")\n",
    "#     #     if href:\n",
    "#     #         content_nodes.append(Embed(href))\n",
    "    \n",
    "#     print(f\"Found {len(content_nodes)} elements\")\n",
    "#     return content_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f115a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(description_html, \"html.parser\")\n",
    "all = soup.find_all()\n",
    "all_list = list(all)\n",
    "divs = soup.find_all(\"div\")\n",
    "divs_list = list(divs)\n",
    "paras = soup.find_all(\"p\")\n",
    "image_containers = soup.find_all(\"div\", class_=\"image-container\")\n",
    "print(len(all))\n",
    "print(f\"Number of divs: {len(divs)}, Number of paragraphs {len(paras)}, Number of image containers {len(image_containers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8232b9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deduplicate_by_containment(elements):\n",
    "    # Create list of (element, outer_html_str) tuples\n",
    "    elems_and_html = [(el, ' '.join(str(el).split())) for el in elements]\n",
    "\n",
    "    keep = []\n",
    "    for i, (el_i, html_i) in enumerate(elems_and_html):\n",
    "        # Check if this element is contained within another (excluding itself)\n",
    "        contained = False\n",
    "        for j, (el_j, html_j) in enumerate(elems_and_html):\n",
    "            if i != j and html_i in html_j:\n",
    "                contained = True\n",
    "                break\n",
    "        if not contained:\n",
    "            keep.append(el_i)\n",
    "    return keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721065dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_top_level = deduplicate_by_containment(all_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d99e698",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_snippet = str(unique_top_level[2])\n",
    "text_nodes = parse_div_to_text_elements(html_snippet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad02c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_div_to_image_elements(div_html):\n",
    "    soup = BeautifulSoup(div_html, \"html.parser\")\n",
    "    img_elements = []\n",
    "    # Find direct <p> children\n",
    "    for p in soup.find_all(\"p\"):\n",
    "        img = p.find(\"img\")  # Find <img> inside <p>\n",
    "        # Get inner HTML (including styled spans, links, etc.)\n",
    "        inner_html = ''.join(str(c) for c in p.contents)\n",
    "\n",
    "        if img:\n",
    "            src_url = img.get(\"src\", \"\")  # Extract src attribute safely\n",
    "            alt_text = img.get(\"alt\", \"\")\n",
    "            # Create a Image node and set properties\n",
    "            # https://developers.arcgis.com/python/latest/api-reference/arcgis.apps.storymap.html#arcgis.apps.storymap.story_content.Image\n",
    "            img_node = Image(path=src_url)\n",
    "            img_node.alt_text = alt_text\n",
    "            img_node.caption = \"\"\n",
    "            img_node.link = \"\"\n",
    "            img_node.image = src_url  # Assign image property\n",
    "            \n",
    "            img_elements.append(img_node)\n",
    "    return img_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69306a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unique_top_level[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fd8eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_snippet = str(unique_top_level[0])\n",
    "text_nodes1 = parse_div_to_text_elements(html_snippet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9771acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_snippet = str(unique_top_level[0])\n",
    "img_nodes1 = parse_div_to_image_elements(img_snippet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f94cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_node in img_nodes1:\n",
    "    story.add(img_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427c451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(story.content_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d31607",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(story.content_list[3].properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59f90ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_element = deduplicate_by_containment(unique_top_level[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e04da20",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_snippet2 = str(first_element[2])\n",
    "print(html_snippet2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecefef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_html_colors_preserve_html(html_text):\n",
    "    soup = BeautifulSoup(html_text, \"html.parser\")\n",
    "    # Iterate over tags that can have styles: div, span, strong, em, p, etc.\n",
    "    for tag in soup.find_all(True):\n",
    "        convert_color_style_to_class(tag)\n",
    "    return str(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c473fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_html = process_html_colors_preserve_html(html_snippet2)\n",
    "print(converted_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf4ec53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the AGSM item id\n",
    "agsm_storymap_id = '808bf08835b740f69022bc1b3593a143'\n",
    "# Fetch the StoryMap Item from AGO\n",
    "agsm_item = Item(gis=gis,itemid=agsm_storymap_id)\n",
    "# Fetch the StoryMap data\n",
    "agsm_data = Item.get_data(agsm_item)\n",
    "if type(agsm_data) == dict:\n",
    "    agsm_item_json = json.dumps(agsm_data)\n",
    "    agsm_item_data = json.loads(agsm_item_json)\n",
    "else:\n",
    "    agsm_item_data = json.loads(agsm_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arcgispro-py3-vscode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
