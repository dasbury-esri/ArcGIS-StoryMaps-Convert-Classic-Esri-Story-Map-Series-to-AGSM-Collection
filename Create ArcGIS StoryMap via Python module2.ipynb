{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e454d37a",
   "metadata": {},
   "source": [
    "# Generalized sketch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70cb43f",
   "metadata": {},
   "source": [
    "TO DO - create conversion tool for classic swipe (second tab in Katrina story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a4a0994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webcolors in c:\\users\\davi6569\\appdata\\local\\esri\\conda\\envs\\arcgispro-py3-vscode\\lib\\site-packages (24.11.1)\n"
     ]
    }
   ],
   "source": [
    "# Install the webcolors package if not already installed\n",
    "!pip install webcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bc65aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, NavigableString, Tag\n",
    "from arcgis.apps.storymap import StoryMap, Themes, Image, Video, Audio, Embed, Map, Button, Text, Gallery, Timeline, Sidecar, Code, Table, TextStyles, Collection, CollectionNavigation\n",
    "from arcgis.gis import GIS, Item\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import webcolors\n",
    "import webbrowser\n",
    "import re, json, requests, sys, time \n",
    "\n",
    "agoNotebook = False\n",
    "\n",
    "# Set Pandas dataframe display options\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns',1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9224ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:  3.11.11 (main, Mar  3 2025, 15:29:37) [MSC v.1938 64 bit (AMD64)]\n",
      "ArcGIS for Python API / StoryMap module version:  2.4.1\n"
     ]
    }
   ],
   "source": [
    "# Print Python and ArcGIS for Python versions\n",
    "# since things can change between versions\n",
    "import sys\n",
    "print(f\"Python version: \",sys.version)\n",
    "import arcgis\n",
    "print(\"ArcGIS for Python API / StoryMap module version: \",arcgis.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6563a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully logged in as: dasbury_storymaps (role: org_admin)\n"
     ]
    }
   ],
   "source": [
    "# Connect to ArcGIS Online\n",
    "# Define the GIS\n",
    "if agoNotebook == False:\n",
    "    import keyring\n",
    "    service_name = \"system\" # Use the default local credential store\n",
    "    success = False # Set initial state\n",
    "\n",
    "    # Ask for the username\n",
    "    while success == False:\n",
    "        username_for_keyring = input(\"Enter your ArcGIS Online username:\") # If you are using VS Code, the text input dialog box appears at the top of the window\n",
    "        # Get the credential object\n",
    "        credential = keyring.get_credential(service_name, username_for_keyring)\n",
    "        # Check if the username is in the credential store\n",
    "        if credential is None:\n",
    "            print(f\"'{username_for_keyring}' is not in the local system's credential store. Try another username.\")\n",
    "        # Retrieve the password, login and set the GIS portal\n",
    "        else:\n",
    "            password_from_keyring = keyring.get_password(\"system\", username_for_keyring)\n",
    "            portal_url = 'https://www.arcgis.com'  \n",
    "            gis = GIS(portal_url, username=username_for_keyring, password=password_from_keyring)\n",
    "            success = True\n",
    "            # Print a success message with username and user's organization role\n",
    "            print(\"Successfully logged in as: \" + gis.properties.user.username, \"(role: \" + gis.properties.user.role + \")\")\n",
    "else:\n",
    "    gis = GIS(\"home\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "051258d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Classic StoryMap item id\n",
    "classic_storymap_id = '597d573e58514bdbbeb53ba2179d2359'\n",
    "# Fetch the StoryMap Item from AGO\n",
    "classic_item = Item(gis=gis,itemid=classic_storymap_id)\n",
    "# Fetch the StoryMap data\n",
    "classic_data = Item.get_data(classic_item)\n",
    "if type(classic_data) == dict:\n",
    "    classic_item_json = json.dumps(classic_data)\n",
    "    classic_item_data = json.loads(classic_item_json)\n",
    "else:\n",
    "    classic_item_data = json.loads(classic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a736a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def color_to_hex(color_value):\n",
    "    color_value = color_value.strip()\n",
    "    # Check for rgb() format\n",
    "    rgb_match = re.match(r'rgb-?(\\d+)-?(\\d+)-?(\\d+)', color_value, re.IGNORECASE)\n",
    "    if rgb_match:\n",
    "        r, g, b = map(int, rgb_match.groups())\n",
    "        return '{:02X}{:02X}{:02X}'.format(r, g, b)\n",
    "    # Check for named color\n",
    "    try:\n",
    "        return webcolors.name_to_hex(color_value.lower())\n",
    "    except ValueError:\n",
    "        pass\n",
    "    # Already hex\n",
    "    if color_value.startswith('#') and len(color_value) == 7:\n",
    "        return color_value.upper()\n",
    "    return None\n",
    "\n",
    "def convert_color_style_to_class(tag):\n",
    "    # Check if tag has 'style' attribute with color\n",
    "    style = tag.get('style', '')\n",
    "    # Regex to find color property (hex, rgb, named colors)\n",
    "    match = re.search(r'color\\s*:\\s*([^;]+)', style, re.IGNORECASE)\n",
    "    if match:\n",
    "        color_value = match.group(1).strip()\n",
    "        # Convert hex (#XXXXXX) to class name, removing #\n",
    "        if color_value.startswith('#'):\n",
    "            class_color = f\"sm-text-color-{color_value[1:].upper()}\"\n",
    "        else:\n",
    "            # For rgb or named color, sanitize usable string (replace spaces/paren)\n",
    "            sanitized = re.sub(r'[\\s\\(\\)]', '', color_value).replace(',', '-')\n",
    "            hex_color = color_to_hex(sanitized)\n",
    "            class_color = f\"sm-text-color-{hex_color}\"\n",
    "        # Remove color from style attribute\n",
    "        new_style = re.sub(r'color\\s*:\\s*[^;]+;?', '', style, flags=re.IGNORECASE).strip()\n",
    "        if new_style:\n",
    "            tag['style'] = new_style\n",
    "        else:\n",
    "            del tag['style']\n",
    "        # Add or append class attribute\n",
    "        if 'class' in tag.attrs:\n",
    "            tag['class'].append(class_color)\n",
    "        else:\n",
    "            tag['class'] = [class_color]\n",
    "\n",
    "def process_html_colors_preserve_html(html_text):\n",
    "    soup = BeautifulSoup(html_text, \"html.parser\")\n",
    "    # Iterate over tags that can have styles: div, span, strong, em, p, etc.\n",
    "    for tag in soup.find_all(True):\n",
    "        convert_color_style_to_class(tag)\n",
    "    return str(soup)\n",
    "\n",
    "def parse_content_element(el):\n",
    "    img_tag = el.find('img')\n",
    "    if img_tag:\n",
    "        src = img_tag.get(\"src\")\n",
    "        alt = img_tag.get(\"alt\", \"\")\n",
    "        link = \"\" # TO DO handle occasions when image is intended to launch a link\n",
    "        # Find figcaption in parent figure or div\n",
    "        figcaption = \"\"\n",
    "        # print(\"img_tag:\", img_tag)\n",
    "        parent_figure = img_tag.find_parent(\"figure\")\n",
    "        # print(\"parent_figure:\", parent_figure)\n",
    "        if parent_figure:\n",
    "            caption_tag = parent_figure.find(\"figcaption\")\n",
    "            # print(\"caption_tag:\", caption_tag)\n",
    "            if caption_tag:\n",
    "                figcaption = caption_tag.get_text(strip=True)\n",
    "        else:\n",
    "            # Try to find figcaption in the parent div\n",
    "            parent_div = img_tag.find_parent(\"div\")\n",
    "            # print(\"parent_div:\", parent_div)\n",
    "            if parent_div:\n",
    "                caption_tag = parent_div.find(\"figcaption\")\n",
    "                # print(\"caption_tag (div):\", caption_tag)\n",
    "                if caption_tag:\n",
    "                    figcaption = caption_tag.get_text(strip=True)\n",
    "        # print(\"Extracted figcaption:\", figcaption, type(figcaption))\n",
    "        img = Image(path=src)\n",
    "        #img.link = link\n",
    "        #img.image = src\n",
    "        return img, figcaption, alt, link\n",
    "\n",
    "    tag_name = el.name\n",
    "    if tag_name == \"p\": # or tag_name in [\"span\", \"strong\", \"em\", \"div\"]:\n",
    "        # Extract inner HTML preserving inline styles\n",
    "        inner_html = ''.join(str(c) for c in el.contents)\n",
    "        processed_html = process_html_colors_preserve_html(inner_html)\n",
    "        return Text(text=processed_html, style=TextStyles.PARAGRAPH)\n",
    "    \n",
    "    # elif tag_name == \"img\" or (tag_name == \"div\" and \"class_\" == \"image-container\"):\n",
    "    #     src = el.get(\"src\")\n",
    "    #     alt = el.get(\"alt\", \"\")\n",
    "    #     link = \"\"\n",
    "    #     if el.get(\"href\"):\n",
    "    #         link = el.get(\"href\")\n",
    "    #     # Find figcaption in parent figure or div\n",
    "    #     figcaption = \"\"\n",
    "    #     parent_figure = img_tag.find_parent(\"figure\")\n",
    "    #     if parent_figure:\n",
    "    #         caption_tag = parent_figure.find(\"figcaption\")\n",
    "    #         if caption_tag:\n",
    "    #             figcaption = caption_tag.get_text(strip=True)\n",
    "    #     else:\n",
    "    #         # Try to find figcaption in the parent div\n",
    "    #         parent_div = img_tag.find_parent(\"div\")\n",
    "    #         if parent_div:\n",
    "    #             caption_tag = parent_div.find(\"figcaption\")\n",
    "    #             if caption_tag:\n",
    "    #                 figcaption = caption_tag.get_text(strip=True)\n",
    "    #     img = Image(path=src, caption=figcaption, alt_text=alt)\n",
    "    #     img.link = link\n",
    "    #     img.image = src  # Assign image property. TO DO fix this for images hosted on AGO\n",
    "    #     return img\n",
    "\n",
    "    elif tag_name == \"video\":\n",
    "        src = el.get(\"src\")\n",
    "        alt = el.get(\"alt\", \"\")\n",
    "        vid = Video(path=src)\n",
    "        vid.alt_text = alt\n",
    "        vid.caption = \"\" # TO DO try to find Classic stories that have Videos with captions\n",
    "        vid.video = src # Assign video property. TO DO fix this for hosted videos\n",
    "        return vid\n",
    "    \n",
    "    elif tag_name == \"audio\":\n",
    "        src = el.get(\"src\")\n",
    "        alt = el.get(\"alt\", \"\")\n",
    "        aud = Audio(path=src)\n",
    "        aud.alt_text = alt\n",
    "        aud.caption = \"\" # TO DO try to find Classic stories that have Audio with captions\n",
    "        aud.audio = src # Assign Audio property. TO DO fix this for hosted videos\n",
    "        return aud\n",
    "    \n",
    "    elif tag_name == \"iframe\" or tag_name == \"embed\":\n",
    "        src = el.get(\"src\") or el.get(\"data-src\")\n",
    "        alt = el.get(\"alt\", \"\")\n",
    "        if src:\n",
    "            emb = Embed(path=src)\n",
    "            emb.alt_text = alt\n",
    "            emb.caption = \"\" # TO DO try to find Classic stories that have Embeds with captions\n",
    "            emb.link = src\n",
    "        return emb\n",
    "\n",
    "    elif tag_name == \"map\":\n",
    "        src = el.get(\"src\")\n",
    "        alt = el.get(\"alt\", \"\")\n",
    "        extent = \"\" #TO DO get extent\n",
    "        layers = \"\" # TO DO get map layers\n",
    "        mp = Map(item=\"\")\n",
    "        mp.alt_text = alt\n",
    "        mp.caption = \"\" # TO DO try to find Classic stories that have Maps in Sidecar panel with captions\n",
    "        mp.map = src\n",
    "        mp.map_layers = layers \n",
    "        mp.set_viewpoint = extent\n",
    "        return aud\n",
    "    \n",
    "    else:\n",
    "        # Fallback for unsupported or unknown types - treat as text\n",
    "        inner_html = ''.join(str(c) for c in el.contents)\n",
    "        processed_html = process_html_colors_preserve_html(inner_html)\n",
    "        return Text(text=processed_html, style=TextStyles.PARAGRAPH)\n",
    "\n",
    "\n",
    "# def deduplicate_by_containment(elements):\n",
    "#     # Create list of (element, outer_html_str) tuples\n",
    "#     elems_and_html = [(el, ' '.join(str(el).split())) for el in elements]\n",
    "\n",
    "#     keep = []\n",
    "#     for i, (el_i, html_i) in enumerate(elems_and_html):\n",
    "#         # Check if this element is contained within another (excluding itself)\n",
    "#         contained = False\n",
    "#         for j, (el_j, html_j) in enumerate(elems_and_html):\n",
    "#             if i != j and html_i in html_j:\n",
    "#                 contained = True\n",
    "#                 break\n",
    "#         if not contained:\n",
    "#             keep.append(el_i)\n",
    "#     return keep\n",
    "\n",
    "# def parse_narrative_html(html_text):\n",
    "#     soup = BeautifulSoup(html_text, \"html.parser\")\n",
    "#     content_nodes = []\n",
    "#     for child in soup.children:\n",
    "#         if isinstance(child, str):\n",
    "#             # Text node (likely whitespace) - skip or wrap in Text()\n",
    "#             node = Text(child)\n",
    "#             continue\n",
    "#         node = parse_content_element(child)\n",
    "#         print(type(node))\n",
    "#         if node:\n",
    "#             content_nodes.append(node)\n",
    "#     #deduped_nodes = deduplicate_by_containment(content_nodes)\n",
    "#     return content_nodes\n",
    "\n",
    "def parse_html_elements(html_snippet):\n",
    "    soup = BeautifulSoup(html_snippet, \"html.parser\")\n",
    "    soup_list = [child for child in soup.contents if getattr(child, 'name', None)]\n",
    "    html_elements = []\n",
    "    for element in soup_list:\n",
    "        for c in element:\n",
    "            if getattr(c, 'name', None):\n",
    "                html_elements.append(c)\n",
    "    return html_elements\n",
    "\n",
    "def convert_html_elements_to_storymap_content(html_elements):\n",
    "    content_nodes = []\n",
    "    image_metadata = []  # To store (img, caption, alt, link) tuples\n",
    "    for el in html_elements:\n",
    "        node = parse_content_element(el)\n",
    "        if isinstance(node, tuple):\n",
    "            img, caption, alt, link = node\n",
    "            content_nodes.append(img)\n",
    "            image_metadata.append((img, caption, alt, link))\n",
    "        elif node:\n",
    "            content_nodes.append(node)\n",
    "    return content_nodes, image_metadata\n",
    "\n",
    "# def extract_content_blocks(html):\n",
    "#     soup = BeautifulSoup(html, \"html.parser\")\n",
    "#     # Find the main container (if present)\n",
    "#     main = soup.find(class_=\"description\") or soup\n",
    "#     # Get all direct children that are tags (not NavigableString)\n",
    "#     blocks = [child for child in main.children if getattr(child, 'name', None)]\n",
    "#     # For each block, get its full HTML string\n",
    "#     elements_list = []\n",
    "#     for block in blocks:\n",
    "#         html_str = str(block).strip()\n",
    "#         # Skip empty blocks\n",
    "#         if html_str and html_str != \"&nbsp;\":\n",
    "#             elements_list.append(html_str)\n",
    "#     return elements_list\n",
    "\n",
    "# def split_nested_blocks(html, target_tags=None):\n",
    "#     if target_tags is None:\n",
    "#         target_tags = [\n",
    "#             {\"name\": \"div\", \"class_\": \"image-container\"},\n",
    "#             {\"name\": \"figure\"}\n",
    "#         ]\n",
    "#     soup = BeautifulSoup(html, \"html.parser\")\n",
    "#     results = []\n",
    "#     # For each target tag, find all matching elements\n",
    "#     for target in target_tags:\n",
    "#         found = soup.find_all(target[\"name\"], class_=target.get(\"class_\"))\n",
    "#         for el in found:\n",
    "#             results.append(str(el).strip())\n",
    "#     # If no target tags found, keep the original block\n",
    "#     if not results:\n",
    "#         results.append(html.strip())\n",
    "#     return results\n",
    "\n",
    "# def filter_parent_blocks(blocks, target_tags=None):\n",
    "#     filtered = []\n",
    "#     for block in blocks:\n",
    "#         split_items = split_nested_blocks(block, target_tags)\n",
    "#         # If split_items contains only the original block, keep it\n",
    "#         if len(split_items) == 1 and split_items[0] == block.strip():\n",
    "#             filtered.append(block.strip())\n",
    "#         # If split_items contains only target elements, keep only those\n",
    "#         elif len(split_items) > 1:\n",
    "#             filtered.extend(split_items)\n",
    "#     return filtered\n",
    "\n",
    "# def filter_parent_blocks_strict(blocks, target_tags=None):\n",
    "#     if target_tags is None:\n",
    "#         target_tags = [\n",
    "#             {\"name\": \"div\", \"class_\": \"image-container\"},\n",
    "#             {\"name\": \"figure\"}\n",
    "#         ]\n",
    "#     filtered = []\n",
    "#     for block in blocks:\n",
    "#         split_items = split_nested_blocks(block, target_tags)\n",
    "#         soup = BeautifulSoup(block, \"html.parser\")\n",
    "#         # Gather all non-whitespace descendants\n",
    "#         descendants = [el for el in soup.descendants if getattr(el, 'name', None)]\n",
    "#         # Gather all target elements\n",
    "#         target_elements = []\n",
    "#         for target in target_tags:\n",
    "#             target_elements.extend(soup.find_all(target[\"name\"], class_=target.get(\"class_\")))\n",
    "#         # If all non-whitespace descendants are target elements, keep only split_items\n",
    "#         if descendants and set(descendants) == set(target_elements):\n",
    "#             filtered.extend(split_items)\n",
    "#         else:\n",
    "#             filtered.append(block.strip())\n",
    "#     return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab211949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract story data\n",
    "classic_story_settings = classic_item_data[\"values\"][\"settings\"]\n",
    "classic_story_theme = classic_story_settings[\"theme\"]\n",
    "classic_story_title = classic_item_data[\"values\"][\"title\"]\n",
    "classic_story_data = classic_item_data[\"values\"][\"story\"]\n",
    "\n",
    "# Extract tabs (entries list)\n",
    "entries = classic_story_data[\"entries\"]\n",
    "\n",
    "# Fetch theme group\n",
    "classic_theme_group = classic_story_theme[\"colors\"][\"group\"]\n",
    "if classic_theme_group == \"dark\":\n",
    "    new_theme = Themes.OBSIDIAN\n",
    "elif classic_theme_group == \"light\":\n",
    "    new_theme = Themes.SUMMIT\n",
    "\n",
    "created_storymaps = []\n",
    "published_storymap_items = []\n",
    "\n",
    "#target_index = 0  # Change to the index of the entry you want to process (0-based)\n",
    "for i, entry in enumerate(entries):\n",
    "    # if i != target_index:\n",
    "    #    continue # Skip all except the target index\n",
    "    # Create a new StoryMap\n",
    "    story = StoryMap()\n",
    "    story.theme(new_theme)\n",
    "\n",
    "    # Create Sidecar immersive section\n",
    "    sidecar = Sidecar(style=\"docked-panel\")\n",
    "\n",
    "    # Add Sidecar to story\n",
    "    story.add(sidecar)\n",
    "\n",
    "    # Determine media content for main stage\n",
    "    media_info = entry.get(\"media\", {})\n",
    "    media_type = media_info.get(\"type\")\n",
    "\n",
    "    media_content = None\n",
    "    if media_type == \"webmap\":\n",
    "        webmap_id = media_info.get('webmap', {}).get('id')\n",
    "        if webmap_id:\n",
    "            media_content = Map(webmap_id)\n",
    "    elif media_type == \"webpage\":\n",
    "        webpage_url = media_info.get(\"webpage\", {}).get(\"url\")\n",
    "        if webpage_url:\n",
    "            media_content = Embed(webpage_url)\n",
    "  \n",
    "    # Fetch content from description (HTML)\n",
    "    description_html = entry.get(\"description\", \"\")\n",
    "\n",
    "    # Convert description HTML to StoryMap content nodes\n",
    "    content_nodes, image_metadata = convert_html_elements_to_storymap_content(parse_html_elements(description_html))\n",
    "\n",
    "    # Create text panel from narrative nodes\n",
    "    text_panel = Text(content_nodes)\n",
    "    #story.add(text_panel)\n",
    "\n",
    "    # Add a slide to the sidecar with main media (no text panel yet)\n",
    "    sidecar.add_slide(contents=content_nodes,media=media_content)\n",
    "\n",
    "    # Assign metadata to each image in contents\n",
    "    for img, caption, alt, link in image_metadata:\n",
    "        if caption:\n",
    "            img.caption = caption\n",
    "        if alt:\n",
    "            img.alt_text = alt\n",
    "        if link:\n",
    "            img.link = link\n",
    "\n",
    "    # Set webmap properties. Map must be added to the story before setting viewpoint\n",
    "    if media_type == \"webmap\":\n",
    "        # Set the extent for the map stage\n",
    "        extent_json = media_info.get('webmap', {}).get('extent')\n",
    "        if extent_json:\n",
    "            media_content.set_viewpoint(extent=extent_json)  # Extent dict per docs\n",
    "        # Set layer visibility (if StoryMap Map object supports)\n",
    "        old_layers = media_info.get('webmap', {}).get('layers', [])\n",
    "        if hasattr(media_content, \"map_layers\"):\n",
    "            for new_lyr in media_content.map_layers:\n",
    "                for old_lyr in old_layers:\n",
    "                    if new_lyr['id'] == old_lyr['id']:\n",
    "                        new_lyr['visible'] = old_lyr['visibility']\n",
    "\n",
    "    # Set Cover properties\n",
    "    cover_properties = story.content_list[0]\n",
    "    cover_properties.byline = \"\"\n",
    "    cover_properties.date = \"none\"\n",
    "    #cover_properties.media = createThumbnail() # figure out a way to create a thumbnail from the first Sidecar media item\n",
    "\n",
    "    # As the Cover class does not include a setting to hide the cover, we hide it by adding the 'config' key\n",
    "    # to the Cover json\n",
    "    for k,v in story.properties['nodes'].items():\n",
    "        if v['type'] == 'storycover':\n",
    "            v['config'] = {'isHidden': 'true'}\n",
    "\n",
    "\n",
    "    # Save and publish storymap\n",
    "    story_title = entry.get(\"title\", \"Untitled Story\")\n",
    "    story.save(title=story_title, tags=[\"auto-created\"], publish=True)\n",
    "\n",
    "    # TO DO add an AGO relationship so if an attempt is made to delete story from My Content a warning is issued that the story\n",
    "    # is included in a Collection (and give the name/id of the Collection(s) where it is referenced)\n",
    "\n",
    "    created_storymaps.append(story)\n",
    "    # Get the item object\n",
    "    if hasattr(story, '_item'):\n",
    "        published_story_item = story._item\n",
    "    else:\n",
    "        print(\"Could not find item for story:\", story.title)\n",
    "        continue\n",
    "\n",
    "    print(f\"Created replica of {story_title}\")\n",
    "\n",
    "    # Open a browser to launch the Story Checker and fully publish the story\n",
    "    story_url = \"https://storymaps.arcgis.com/stories/\"+ published_story_item.id\n",
    "    print(f\"Opening: {published_story_item.title} ({story_url})\")\n",
    "    webbrowser.open(story_url)\n",
    "\n",
    "print(f\"Created {len(created_storymaps)} StoryMaps\")\n",
    "\n",
    "# Pause for 60 seconds\n",
    "print(\"Waiting for 30 seconds for stories to publish...\")\n",
    "time.sleep(30)\n",
    "print(\"Resuming code execution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0522e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a Collection to hold the created StoryMaps\n",
    "collection = Collection()\n",
    "collection_title = classic_item.title\n",
    "storymap_item = []\n",
    "for story in published_storymap_items:\n",
    "    collection.add(item=story, title=story.title)\n",
    "collection.content[0] = title.collection_title\n",
    "collection.theme(new_theme)    \n",
    "\n",
    "collection.save(title=collection_title, tags=[\"auto-created\"], publish=True)\n",
    "published_collection_item = collection._item\n",
    "collection_url = \"https://storymaps.arcgis.com/collections/\"+ published_collection_item.id\n",
    "print(f\"Opening Collection: {collection_title} ({collection_url})\")\n",
    "webbrowser.open(collection_url)\n",
    "print(f\"Created Collection: {collection_title}\")\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "647f357c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'obsidian'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.get_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05736a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudocode for traversing html tree\n",
    "# get all leaf nodes\n",
    "# if node is a leaf node (no children)\n",
    "#     recursively check its parents until the parent is equal to the root node.\n",
    "#     step down one level\n",
    "#     check for img, video, audio, iframe, embed, map tags\n",
    "#     if no other tags found, mark as text node\n",
    "#     if img, video, audio, iframe, embed, map tag found mark as that type\n",
    "#     traverse up tree until a <p>, <div> or <span>is found\n",
    "#     once a <p> is found, check if its parent is a <div class=image-container>, if so mark as Image()\n",
    "#     once a <div> is found, check if its parent is a <Figure class=caption>, if so process as Image() with caption\n",
    "#     once a <span> is found, check if its parent is a <span>\n",
    "#     otherwise, capture all descendant tags and process the node as its marked type (Text | Image | Video | Audio | Embed | Map | Button | Code | Table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b698bba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(description_html, \"html.parser\")\n",
    "soup_content = list(soup.children)\n",
    "# soup_content_collapsed = [child for child in soup_content if getattr(child, 'name', None)]\n",
    "# for el in soup_content_collapsed[0]:\n",
    "#     el_nodes = []\n",
    "#     for tag in el.find_all(True):  # All tags, nested included\n",
    "#         # A leaf node has no child tags\n",
    "#         if not tag.find_all(True):\n",
    "#             el_nodes.append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f084bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(description_html, \"html.parser\")\n",
    "leaf_nodes = []\n",
    "\n",
    "for tag in soup.find_all(True):  # All tags, nested included\n",
    "    # A leaf node has no child tags\n",
    "    if not tag.find_all(True):\n",
    "        leaf_nodes.append(tag)\n",
    "\n",
    "# leaf_nodes now contains all leaf elements\n",
    "print(len(leaf_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c5ad69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(leaf_nodes[15].parent.parent.parent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
