{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e454d37a",
   "metadata": {},
   "source": [
    "# Generalized sketch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70cb43f",
   "metadata": {},
   "source": [
    "TO DO - create conversion tool for classic swipe (second tab in Katrina story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bc65aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, NavigableString, Tag\n",
    "from arcgis.apps.storymap import StoryMap, Themes, Image, Video, Audio, Embed, Map, Button, Text, Gallery, Timeline, Sidecar, Code, Table, TextStyles\n",
    "from arcgis.gis import GIS, Item\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import re, json, requests, sys, time \n",
    "\n",
    "agoNotebook = False\n",
    "\n",
    "# Set Pandas dataframe display options\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns',1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9224ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:  3.11.11 (main, Mar  3 2025, 15:29:37) [MSC v.1938 64 bit (AMD64)]\n",
      "ArcGIS for Python API / StoryMap module version:  2.4.1\n"
     ]
    }
   ],
   "source": [
    "# Print Python and ArcGIS for Python versions\n",
    "# since things can change between versions\n",
    "import sys\n",
    "print(f\"Python version: \",sys.version)\n",
    "import arcgis\n",
    "print(\"ArcGIS for Python API / StoryMap module version: \",arcgis.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6563a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully logged in as: dasbury_storymaps (role: org_admin)\n"
     ]
    }
   ],
   "source": [
    "# Connect to ArcGIS Online\n",
    "# Define the GIS\n",
    "if agoNotebook == False:\n",
    "    import keyring\n",
    "    service_name = \"system\" # Use the default local credential store\n",
    "    success = False # Set initial state\n",
    "\n",
    "    # Ask for the username\n",
    "    while success == False:\n",
    "        username_for_keyring = input(\"Enter your ArcGIS Online username:\") # If you are using VS Code, the text input dialog box appears at the top of the window\n",
    "        # Get the credential object\n",
    "        credential = keyring.get_credential(service_name, username_for_keyring)\n",
    "        # Check if the username is in the credential store\n",
    "        if credential is None:\n",
    "            print(f\"'{username_for_keyring}' is not in the local system's credential store. Try another username.\")\n",
    "        # Retrieve the password, login and set the GIS portal\n",
    "        else:\n",
    "            password_from_keyring = keyring.get_password(\"system\", username_for_keyring)\n",
    "            portal_url = 'https://www.arcgis.com'  \n",
    "            gis = GIS(portal_url, username=username_for_keyring, password=password_from_keyring)\n",
    "            success = True\n",
    "            # Print a success message with username and user's organization role\n",
    "            print(\"Successfully logged in as: \" + gis.properties.user.username, \"(role: \" + gis.properties.user.role + \")\")\n",
    "else:\n",
    "    gis = GIS(\"home\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "051258d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Classic StoryMap item id\n",
    "classic_storymap_id = '597d573e58514bdbbeb53ba2179d2359'\n",
    "# Fetch the StoryMap Item from AGO\n",
    "classic_item = Item(gis=gis,itemid=classic_storymap_id)\n",
    "# Fetch the StoryMap data\n",
    "classic_data = Item.get_data(classic_item)\n",
    "if type(classic_data) == dict:\n",
    "    classic_item_json = json.dumps(classic_data)\n",
    "    classic_item_data = json.loads(classic_item_json)\n",
    "else:\n",
    "    classic_item_data = json.loads(classic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a736a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def convert_color_style_to_class(tag):\n",
    "    # Check if tag has 'style' attribute with color\n",
    "    style = tag.get('style', '')\n",
    "    # Regex to find color property (hex, rgb, named colors)\n",
    "    match = re.search(r'color\\s*:\\s*([^;]+)', style, re.IGNORECASE)\n",
    "    if match:\n",
    "        color_value = match.group(1).strip()\n",
    "        # Convert hex (#XXXXXX) to class name, removing #\n",
    "        if color_value.startswith('#'):\n",
    "            class_color = f\"sm-text-color-{color_value[1:].upper()}\"\n",
    "        else:\n",
    "            # For rgb or named color, sanitize usable string (replace spaces/paren)\n",
    "            sanitized = re.sub(r'[\\s\\(\\)]', '', color_value).replace(',', '-')\n",
    "            class_color = f\"sm-text-color-{sanitized.upper()}\"\n",
    "        # Remove color from style attribute\n",
    "        new_style = re.sub(r'color\\s*:\\s*[^;]+;?', '', style, flags=re.IGNORECASE).strip()\n",
    "        if new_style:\n",
    "            tag['style'] = new_style\n",
    "        else:\n",
    "            del tag['style']\n",
    "        # Add or append class attribute\n",
    "        if 'class' in tag.attrs:\n",
    "            tag['class'].append(class_color)\n",
    "        else:\n",
    "            tag['class'] = [class_color]\n",
    "\n",
    "def process_html_colors_preserve_html(html_text):\n",
    "    soup = BeautifulSoup(html_text, \"html.parser\")\n",
    "    # Iterate over tags that can have styles: div, span, strong, em, p, etc.\n",
    "    for tag in soup.find_all(True):\n",
    "        convert_color_style_to_class(tag)\n",
    "    return str(soup)\n",
    "\n",
    "def parse_content_element(el):\n",
    "    tag_name = el.name\n",
    "    if tag_name == \"p\": # or tag_name in [\"span\", \"strong\", \"em\", \"div\"]:\n",
    "        # Extract inner HTML preserving inline styles\n",
    "        inner_html = ''.join(str(c) for c in el.contents)\n",
    "        processed_html = process_html_colors_preserve_html(inner_html)\n",
    "        return Text(text=processed_html, style=TextStyles.PARAGRAPH)\n",
    "    \n",
    "    elif tag_name == \"img\":\n",
    "        src = el.get(\"src\")\n",
    "        alt = el.get(\"alt\", \"\")\n",
    "        link = \"\"\n",
    "        if el.get(\"href\"):\n",
    "            link = el.get(\"href\")\n",
    "        img = Image(path=src)\n",
    "        img.alt_text = alt\n",
    "        img.caption = \"\" # TO DO try to find Classic stories that have images with captions\n",
    "        img.link = link\n",
    "        img.image = src  # Assign image property. TO DO fix this for images hosted on AGO\n",
    "        return img\n",
    "\n",
    "    elif tag_name == \"video\":\n",
    "        src = el.get(\"src\")\n",
    "        alt = el.get(\"alt\", \"\")\n",
    "        vid = Video(path=src)\n",
    "        vid.alt_text = alt\n",
    "        vid.caption = \"\" # TO DO try to find Classic stories that have Videos with captions\n",
    "        vid.video = src # Assign video property. TO DO fix this for hosted videos\n",
    "        return vid\n",
    "    \n",
    "    elif tag_name == \"audio\":\n",
    "        src = el.get(\"src\")\n",
    "        alt = el.get(\"alt\", \"\")\n",
    "        aud = Audio(path=src)\n",
    "        aud.alt_text = alt\n",
    "        aud.caption = \"\" # TO DO try to find Classic stories that have Audio with captions\n",
    "        aud.audio = src # Assign Audio property. TO DO fix this for hosted videos\n",
    "        return aud\n",
    "    \n",
    "    elif tag_name == \"iframe\" or tag_name == \"embed\":\n",
    "        src = el.get(\"src\") or el.get(\"data-src\")\n",
    "        alt = el.get(\"alt\", \"\")\n",
    "        if src:\n",
    "            emb = Embed(path=src)\n",
    "            emb.alt_text = alt\n",
    "            emb.caption = \"\" # TO DO try to find Classic stories that have Embeds with captions\n",
    "            emb.link = src\n",
    "        return emb\n",
    "\n",
    "    elif tag_name == \"map\":\n",
    "        src = el.get(\"src\")\n",
    "        alt = el.get(\"alt\", \"\")\n",
    "        extent = \"\" #TO DO get extent\n",
    "        layers = \"\" # TO DO get map layers\n",
    "        mp = Map(item=\"\")\n",
    "        mp.alt_text = alt\n",
    "        mp.caption = \"\" # TO DO try to find Classic stories that have Maps in Sidecar panel with captions\n",
    "        mp.map = src\n",
    "        mp.map_layers = layers \n",
    "        mp.set_viewpoint = extent\n",
    "        return aud\n",
    "    \n",
    "    else:\n",
    "        # Fallback for unsupported or unknown types - treat as text\n",
    "        inner_html = ''.join(str(c) for c in el.contents)\n",
    "        processed_html = process_html_colors_preserve_html(inner_html)\n",
    "        return Text(text=processed_html, style=TextStyles.PARAGRAPH)\n",
    "\n",
    "# def deduplicate_by_containment(elements):\n",
    "#     # Create list of (element, outer_html_str) tuples\n",
    "#     elems_and_html = [(el, ' '.join(str(el).split())) for el in elements]\n",
    "\n",
    "#     keep = []\n",
    "#     for i, (el_i, html_i) in enumerate(elems_and_html):\n",
    "#         # Check if this element is contained within another (excluding itself)\n",
    "#         contained = False\n",
    "#         for j, (el_j, html_j) in enumerate(elems_and_html):\n",
    "#             if i != j and html_i in html_j:\n",
    "#                 contained = True\n",
    "#                 break\n",
    "#         if not contained:\n",
    "#             keep.append(el_i)\n",
    "#     return keep\n",
    "\n",
    "# def parse_narrative_html(html_text):\n",
    "#     soup = BeautifulSoup(html_text, \"html.parser\")\n",
    "#     content_nodes = []\n",
    "#     for child in soup.children:\n",
    "#         if isinstance(child, str):\n",
    "#             # Text node (likely whitespace) - skip or wrap in Text()\n",
    "#             node = Text(child)\n",
    "#             continue\n",
    "#         node = parse_content_element(child)\n",
    "#         print(type(node))\n",
    "#         if node:\n",
    "#             content_nodes.append(node)\n",
    "#     #deduped_nodes = deduplicate_by_containment(content_nodes)\n",
    "#     return content_nodes\n",
    "\n",
    "def parse_html_elements(html_snippet):\n",
    "    soup = BeautifulSoup(html_snippet, \"html.parser\")\n",
    "    soup_list = [child for child in soup.contents if getattr(child, 'name', None)]\n",
    "    html_elements = []\n",
    "    for element in soup_list:\n",
    "        for c in element:\n",
    "            if getattr(c, 'name', None):\n",
    "                html_elements.append(c)\n",
    "    return html_elements\n",
    "\n",
    "def convert_html_elements_to_storymap_content(html_elements):\n",
    "    content_nodes = []\n",
    "    for el in html_elements:\n",
    "        node = parse_content_element(el)\n",
    "        if node:\n",
    "            content_nodes.append(node)\n",
    "    return content_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ab211949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract story data\n",
    "classic_story_settings = classic_item_data[\"values\"][\"settings\"]\n",
    "classic_story_theme = classic_story_settings[\"theme\"]\n",
    "classic_story_title = classic_item_data[\"values\"][\"title\"]\n",
    "classic_story_data = classic_item_data[\"values\"][\"story\"]\n",
    "\n",
    "# Extract tabs (entries list)\n",
    "entries = classic_story_data[\"entries\"]\n",
    "\n",
    "# Fetch theme group\n",
    "classic_theme_group = classic_story_theme[\"colors\"][\"group\"]\n",
    "if classic_theme_group == \"dark\":\n",
    "    new_theme = Themes.OBSIDIAN\n",
    "elif classic_theme_group == \"light\":\n",
    "    new_theme = Themes.SUMMIT\n",
    "\n",
    "created_storymaps = []\n",
    "# loop_limit = 0 # Zero indexed. For testing/debugging only\n",
    "target_index = 5  # Change to the index of the entry you want to process (0-based)\n",
    "for i, entry in enumerate(entries):\n",
    "    if i != target_index:\n",
    "        continue # Skip all except the target index\n",
    "    # Create a new StoryMap\n",
    "    story = StoryMap()\n",
    "    story.theme(new_theme)\n",
    "\n",
    "    # Create Sidecar immersive section\n",
    "    sidecar = Sidecar(style=\"docked-panel\")\n",
    "\n",
    "    # Add Sidecar to story\n",
    "    story.add(sidecar)\n",
    "\n",
    "    # Determine media content for main stage\n",
    "    media_info = entry.get(\"media\", {})\n",
    "    media_type = media_info.get(\"type\")\n",
    "\n",
    "    media_content = None\n",
    "    if media_type == \"webmap\":\n",
    "        webmap_id = media_info.get('webmap', {}).get('id')\n",
    "        if webmap_id:\n",
    "            media_content = Map(webmap_id)\n",
    "    elif media_type == \"webpage\":\n",
    "        webpage_url = media_info.get(\"webpage\", {}).get(\"url\")\n",
    "        if webpage_url:\n",
    "            media_content = Embed(webpage_url)\n",
    "\n",
    "    # Fetch content from description (HTML)\n",
    "    description_html = entry.get(\"description\", \"\")\n",
    "\n",
    "    html_elements = parse_html_elements(description_html)\n",
    "\n",
    "    content_nodes = convert_html_elements_to_storymap_content(html_elements)\n",
    "\n",
    "    #content_nodes = []\n",
    "    # for child in soup.children:\n",
    "    #     if isinstance(child, str):\n",
    "    #         # Text node (likely whitespace) - skip or wrap in Text()\n",
    "    #         node = Text(child)\n",
    "    #         continue\n",
    "    #     node = parse_content_element(child)\n",
    "    #     print(type(node))\n",
    "    #     if node:\n",
    "    #         content_nodes.append(node)\n",
    "    # #deduped_nodes = deduplicate_by_containment(content_nodes)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e29bb930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Text, Text, Text, Text, Text, Text, Text, Text, Text, Text]\n"
     ]
    }
   ],
   "source": [
    "print(content_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05736a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudocode for traversing html tree\n",
    "# get all leaf nodes\n",
    "# if node is a leaf node (no children)\n",
    "#     recursively check its parents until the parent is equal to the root node.\n",
    "#     step down one level\n",
    "#     check for img, video, audio, iframe, embed, map tags\n",
    "#     if no other tags found, mark as text node\n",
    "#     if img, video, audio, iframe, embed, map tag found mark as that type\n",
    "#     traverse up tree until a <p>, <div> or <span>is found\n",
    "#     once a <p> is found, check if its parent is a <div class=image-container>, if so mark as Image()\n",
    "#     once a <div> is found, check if its parent is a <Figure class=caption>, if so process as Image() with caption\n",
    "#     once a <span> is found, check if its parent is a <span>\n",
    "#     otherwise, capture all descendant tags and process the node as its marked type (Text | Image | Video | Audio | Embed | Map | Button | Code | Table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b698bba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(description_html, \"html.parser\")\n",
    "soup_content = list(soup.children)\n",
    "# soup_content_collapsed = [child for child in soup_content if getattr(child, 'name', None)]\n",
    "# for el in soup_content_collapsed[0]:\n",
    "#     el_nodes = []\n",
    "#     for tag in el.find_all(True):  # All tags, nested included\n",
    "#         # A leaf node has no child tags\n",
    "#         if not tag.find_all(True):\n",
    "#             el_nodes.append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "90f084bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(description_html, \"html.parser\")\n",
    "leaf_nodes = []\n",
    "\n",
    "for tag in soup.find_all(True):  # All tags, nested included\n",
    "    # A leaf node has no child tags\n",
    "    if not tag.find_all(True):\n",
    "        leaf_nodes.append(tag)\n",
    "\n",
    "# leaf_nodes now contains all leaf elements\n",
    "print(len(leaf_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "74c5ad69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"image-container\">\n",
      "<div class=\"image-container\">\n",
      "<p style=\"text-align:center\"><img alt=\"\" height=\"203\" src=\"https://lh3.googleusercontent.com/-vOXG3mav0d4/Vcorv5d0CMI/AAAAAAAAAAk/A0h7kcDb-ZI/s1600/Flood%252520Legend.png\" width=\"351\"/></p>\n",
      "</div>\n",
      "</div>\n",
      "<p><strong><span style=\"color:rgb(229, 250, 132)\"><span style=\"font-size:20px\"><span>Katrina flooded 80% of New Orleans, resulting in</span></span></span><span style=\"font-size:20px\"><span style=\"color:#E2F782\"> </span><em><a href=\"http://www.datacenterresearch.org/data-resources/katrina/facts-for-impact/\" target=\"_blank\"><span style=\"color:#E2F782\">$135 billion in damages</span></a></em><span style=\"color:#E2F782\">. </span></span></strong></p>\n",
      "<p><span style=\"font-size:14px\"> </span></p>\n",
      "<p><span style=\"font-size:12px\"><strong><span style=\"color:rgb(226, 247, 130)\">Swipe the divider</span></strong> to see where water settled following Katrina. Note that the <em>actual</em> flooding extent went beyond these dark areas before water levels reached equilibrium. </span><span style=\"font-size:12px\">The storm destroyed numerous levees and other flood-prevention features guarding the city -- </span><strong><span style=\"font-size:12px\"><span style=\"color:rgb(226, 247, 130)\">click on each point</span></span></strong><span style=\"font-size:12px\"> for details. </span></p>\n",
      "<div class=\"image-container activate-fullscreen\">\n",
      "<figure class=\"caption\">\n",
      "<div class=\"image-container activate-fullscreen\"><img alt=\"\" src=\"https://lh3.googleusercontent.com/-V31a8fKTB6A/VdNZnWdlw3I/AAAAAAAAAKs/h_NQZzznchI/s1600/Industrial%252520Canal.jpg\"/></div>\n",
      "<figcaption>Industrial Canal Breach in Lower 9th Ward (NOAA)</figcaption>\n",
      "</figure>\n",
      "</div>\n",
      "<p><span style=\"font-size:10px\">Data Source: <a href=\"https://pubs.usgs.gov/ds/470/ds470.pdf\" target=\"_blank\">Terrestrial lidar datasets of New Orleans levee failures from Hurricane Katrina, August 29, 2005: U.S. Geological Survey Data Series</a></span></p>\n",
      "<p><span style=\"font-size:10px\">Imagery Sources: <a href=\"http://earthobservatory.nasa.gov/?eocn=topnav&amp;eoci=logo\" target=\"_blank\">NASA Earth Observatory</a>, <a href=\"http://storms.ngs.noaa.gov/katrina/\" target=\"_blank\">NOAA National Geodetic Survey</a></span></p>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(leaf_nodes[15].parent.parent.parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1262aabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_color_style_to_class(tag):\n",
    "    # Check if tag has 'style' attribute with color\n",
    "    style = tag.get('style', '')\n",
    "    # Regex to find color property (hex, rgb, named colors)\n",
    "    match = re.search(r'color\\s*:\\s*([^;]+)', style, re.IGNORECASE)\n",
    "    if match:\n",
    "        color_value = match.group(1).strip()\n",
    "        # Convert hex (#XXXXXX) to class name, removing #\n",
    "        if color_value.startswith('#'):\n",
    "            class_color = f\"sm-text-color-{color_value[1:].upper()}\"\n",
    "        else:\n",
    "            # For rgb or named color, sanitize usable string (replace spaces/paren)\n",
    "            sanitized = re.sub(r'[\\s\\(\\)]', '', color_value).replace(',', '-')\n",
    "            class_color = f\"sm-text-color-{sanitized.upper()}\"\n",
    "        # Remove color from style attribute\n",
    "        new_style = re.sub(r'color\\s*:\\s*[^;]+;?', '', style, flags=re.IGNORECASE).strip()\n",
    "        if new_style:\n",
    "            tag['style'] = new_style\n",
    "        else:\n",
    "            del tag['style']\n",
    "        # Add or append class attribute\n",
    "        if 'class' in tag.attrs:\n",
    "            tag['class'].append(class_color)\n",
    "        else:\n",
    "            tag['class'] = [class_color]\n",
    "\n",
    "def process_html_colors_preserve_html(html_text):\n",
    "    soup = BeautifulSoup(html_text, \"html.parser\")\n",
    "    # Iterate over tags that can have styles: div, span, strong, em, p, etc.\n",
    "    for tag in soup.find_all(True):\n",
    "        convert_color_style_to_class(tag)\n",
    "    return str(soup)\n",
    "\n",
    "def soupify_html(html_snippet):\n",
    "    soup = BeautifulSoup(html_snippet, \"html.parser\")\n",
    "    soup_contents = soup.contents\n",
    "    result = []\n",
    "    for child in soup.children:\n",
    "        result.extend(parse_html_to_storymap_content(child))\n",
    "    return result\n",
    "\n",
    "def parse_html_to_storymap_content(element):\n",
    "    content_items = []\n",
    "    # If it's a NavigableString (text node), skip or wrap as needed\n",
    "    if isinstance(element, NavigableString):\n",
    "        text = element.strip()\n",
    "        if text:\n",
    "            content_items.append(text)\n",
    "        return content_items\n",
    "\n",
    "    elif element.name == \"img\":\n",
    "        # Create Image object\n",
    "        img = element\n",
    "        # img = Image(path=tag.get(\"src\", \"\"))\n",
    "        # img.alt_text = tag.get(\"alt\", \"\")\n",
    "        # img.caption = \"\" # TO DO try to find Classic stories that have images with captions\n",
    "        # img.link = tag.get(\"href\", \"\")\n",
    "        # img.image = tag.get(\"src\", \"\")  # Assign image property. TO DO fix this for images hosted on AGO\n",
    "        content_items.append(img)\n",
    "    elif element.name == \"p\":\n",
    "        # Handle styled paragraphs and links inside\n",
    "        inner_html = ''.join(str(c) for c in element.contents)\n",
    "        processed_html = process_html_colors_preserve_html(inner_html)\n",
    "        content_items.append(processed_html)\n",
    "        # Optionally, process spans/links inside <p>\n",
    "        #content_items.append(Text(text=processed_html, style=TextStyles.PARAGRAPH))\n",
    "\n",
    "    # Add more elifs for other types (span, video, etc.) as needed\n",
    "    \n",
    "    # For container elements, recurse into children\n",
    "    # Only recurse if element is a Tag\n",
    "    if isinstance(element, Tag):    \n",
    "        for child in element.children:\n",
    "            content_items.extend(parse_html_to_storymap_content(child))\n",
    "    return content_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e8fceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = soupify_html(description_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df57797",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5f2845",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(description_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb59e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5452e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    narrative_nodes = parse_narrative_html(description_html)\n",
    "\n",
    "    # Create text panel from narrative nodes\n",
    "    text_panel = Text(narrative_nodes)\n",
    "    #story.add(text_panel)\n",
    "\n",
    "    # Add a slide to the sidecar with text panel and main media\n",
    "    sidecar.add_slide(contents=narrative_nodes, media=media_content)  \n",
    "\n",
    "    # Set webmap properties. Map must be added to the story before setting viewpoint\n",
    "    if media_type == \"webmap\":\n",
    "        # Set the extent for the map stage\n",
    "        extent_json = media_info.get('webmap', {}).get('extent')\n",
    "        if extent_json:\n",
    "            media_content.set_viewpoint(extent=extent_json)  # Extent dict per docs\n",
    "        # Set layer visibility (if StoryMap Map object supports)\n",
    "        old_layers = media_info.get('webmap', {}).get('layers', [])\n",
    "        if hasattr(media_content, \"map_layers\"):\n",
    "            for new_lyr in media_content.map_layers:\n",
    "                for old_lyr in old_layers:\n",
    "                    if new_lyr['id'] == old_lyr['id']:\n",
    "                        new_lyr['visible'] = old_lyr['visibility']\n",
    "    \n",
    "    # Set Cover properties\n",
    "    cover_properties = story.content_list[0]\n",
    "    cover_properties.byline = \"\"\n",
    "    cover_properties.date = \"none\"\n",
    "    #cover_properties.media = createThumbnail() # figure out a way to create a thumbnail from the first Sidecar media item\n",
    "\n",
    "    # As the Cover class does not include a setting to hide the cover, we hide it by adding the 'config' key\n",
    "    # to the Cover json\n",
    "    for k,v in story.properties['nodes'].items():\n",
    "        if v['type'] == 'storycover':\n",
    "            v['config'] = {'isHidden': 'true'}\n",
    "\n",
    "\n",
    "    # Save and publish storymap\n",
    "    story_title = entry.get(\"title\", \"Untitled Story\")\n",
    "    story.save(title=story_title, tags=[\"auto-created\"], publish=True)\n",
    "\n",
    "    # TO DO add an AGO relationship so if an attempt is made to delete story from My Content a warning is issued that the story\n",
    "    # is included in a Collection (and give the name/id of the Collection(s) where it is referenced)\n",
    "\n",
    "    created_storymaps.append(story)\n",
    "    print(f\"Created replica of {story_title}\")\n",
    "    # if i == loop_limit:\n",
    "    #     break\n",
    "\n",
    "print(f\"Created {len(created_storymaps)} StoryMaps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961ce0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(description_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cafd5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(narrative_nodes[3].properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ca53bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_content_element(el):\n",
    "    tag_name = el.name\n",
    "    if tag_name == \"p\" or tag_name in [\"span\", \"strong\", \"em\", \"div\"]:\n",
    "        # Extract inner HTML preserving inline styles\n",
    "        inner_html = ''.join(str(c) for c in el.contents)\n",
    "        processed_html = process_html_colors_preserve_html(inner_html)\n",
    "        return Text(text=processed_html, style=TextStyles.PARAGRAPH)\n",
    "    \n",
    "    elif tag_name == \"img\":\n",
    "        src = el.get(\"src\")\n",
    "        alt = el.get(\"alt\", \"\")\n",
    "        link = \"\"\n",
    "        if el.get(\"href\"):\n",
    "            link = el.get(\"href\")\n",
    "        img = Image(path=src)\n",
    "        img.alt_text = alt\n",
    "        img.caption = \"\" # TO DO try to find Classic stories that have images with captions\n",
    "        img.link = link\n",
    "        img.image = src  # Assign image property. TO DO fix this for images hosted on AGO\n",
    "        return img\n",
    "\n",
    "    elif tag_name == \"video\":\n",
    "        src = el.get(\"src\")\n",
    "        alt = el.get(\"alt\", \"\")\n",
    "        vid = Video(path=src)\n",
    "        vid.alt_text = alt\n",
    "        vid.caption = \"\" # TO DO try to find Classic stories that have Videos with captions\n",
    "        vid.video = src # Assign video property. TO DO fix this for hosted videos\n",
    "        return vid\n",
    "    \n",
    "    elif tag_name == \"audio\":\n",
    "        src = el.get(\"src\")\n",
    "        alt = el.get(\"alt\", \"\")\n",
    "        aud = Audio(path=src)\n",
    "        aud.alt_text = alt\n",
    "        aud.caption = \"\" # TO DO try to find Classic stories that have Audio with captions\n",
    "        aud.audio = src # Assign Audio property. TO DO fix this for hosted videos\n",
    "        return aud\n",
    "    \n",
    "    elif tag_name == \"iframe\" or tag_name == \"embed\":\n",
    "        src = el.get(\"src\") or el.get(\"data-src\")\n",
    "        alt = el.get(\"alt\", \"\")\n",
    "        if src:\n",
    "            emb = Embed(path=src)\n",
    "            emb.alt_text = alt\n",
    "            emb.caption = \"\" # TO DO try to find Classic stories that have Embeds with captions\n",
    "            emb.link = src\n",
    "        return emb\n",
    "\n",
    "    elif tag_name == \"map\":\n",
    "        src = el.get(\"src\")\n",
    "        alt = el.get(\"alt\", \"\")\n",
    "        extent = \"\" #TO DO get extent\n",
    "        layers = \"\" # TO DO get map layers\n",
    "        mp = Map(item=\"\")\n",
    "        mp.alt_text = alt\n",
    "        mp.caption = \"\" # TO DO try to find Classic stories that have Maps in Sidecar panel with captions\n",
    "        mp.map = src\n",
    "        mp.map_layers = layers \n",
    "        mp.set_viewpoint = extent\n",
    "        return aud\n",
    "    \n",
    "    else:\n",
    "        # Fallback for unsupported or unknown types - treat as text\n",
    "        inner_html = ''.join(str(c) for c in el.contents)\n",
    "        processed_html = process_html_colors_preserve_html(inner_html)\n",
    "        print(\"Type check failed. Returning Text object as default.\")\n",
    "        return Text(text=processed_html, style=TextStyles.PARAGRAPH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79b7099",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(description_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd0639e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_html_recursive(element):\n",
    "    content_nodes = []\n",
    "\n",
    "    if isinstance(element, NavigableString):\n",
    "        # Skip whitespace text nodes or wrap small text as Text if relevant\n",
    "        text = element.string.strip()\n",
    "        if text:\n",
    "            content_nodes.append(Text(text=text, style=TextStyles.PARAGRAPH))\n",
    "        return content_nodes\n",
    "\n",
    "    if element.name == 'img':\n",
    "        src = element.get('src')\n",
    "        alt = element.get('alt', '')\n",
    "        img_node = Image(path=src)\n",
    "        img_node.alt_text = alt\n",
    "        content_nodes.append(img_node)\n",
    "        return content_nodes\n",
    "\n",
    "    if element.name in ['p', 'span', 'strong', 'em', 'div', 'section', 'figure', 'caption']:\n",
    "        # For container text tags, process children individually\n",
    "        for child in element.children:\n",
    "            content_nodes.extend(parse_html_recursive(child))\n",
    "        return content_nodes\n",
    "\n",
    "    # For other tags, fallback to converting the full inner HTML as one Text node\n",
    "    inner_html = ''.join(str(c) for c in element.contents)\n",
    "    if inner_html.strip():\n",
    "        text_node = Text(text=inner_html, style=TextStyles.PARAGRAPH)\n",
    "        content_nodes.append(text_node)\n",
    "    return content_nodes\n",
    "\n",
    "def parse_narrative_html(html_text):\n",
    "    soup = BeautifulSoup(html_text, \"html.parser\")\n",
    "    content_nodes = []\n",
    "    for child in soup.children:\n",
    "        # if isinstance(child, str):\n",
    "        #     # Text node (likely whitespace) - skip or wrap in Text()\n",
    "        #     node = Text(text=child)\n",
    "        #     print(\"Node is raw text\")\n",
    "        #     continue\n",
    "        print(child)\n",
    "        node = parse_html_recursive(child)\n",
    "        print(type(node), node)\n",
    "        if node:\n",
    "            content_nodes.append(node)\n",
    "    #deduped_nodes = deduplicate_by_containment(content_nodes)\n",
    "    return content_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f182070",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = parse_narrative_html(description_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a36c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nodes[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
